### 20240126：牛OR基因community在各组织表达

##### 提取NCBI NR形式的OR

```shell
cut -f 4 /share/home/yzwl_zhouy/penglingwei/OR/ref/CORD/cattle.tsv | awk 'NR>1{print}' | grep -v "^-"
```

##### 转换成ensembl_gene_id

```
转换网址：https://biodbnet-abcc.ncifcrf.gov/db/db2db.php
```

<img src="0记录本/image-20240126224536732.png" alt="image-20240126224536732" style="zoom: 33%;" />

##### 爬虫cattleGTEx以获取每个OR基因的组织表达谱表达

```
cattleGTEx地址：https://cattlegtex.farmgtex.org/search
```

##### 生成绘图所需文件

建立蛋白与community的 关系

```shell
cut -f 4,8 /share/home/yzwl_zhouy/penglingwei/OR/ref/CORD/cattle.tsv | awk 'NR>1&&$1!="---"{split($1, s, ".") ; print s[1]"\t"$2}' > protein2community.tsv
```

建立样本和组织的关系

```shell
cat gene_expression/ENSBTAG00000051648.gene_tpm.tsv | awk -F "\t" '{print $3"\t"$1}' > sample2tissu
e.tsv
```

生成OR基因为行名样本为列名表达矩阵，建立基因和community关系

```python
wd = "/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx/cattle"
import pandas as pd
import os
df1 = pd.read_table("protein2gene.tsv", header=0, sep="\t")
df2 = pd.read_table("protein2community.tsv", header=0, sep="\t")
df0 = pd.merge(df1, df2, on="protein", how="inner").set_index("gene")

lst = []
dfs = pd.DataFrame()
for tsv in os.listdir("gene_expression"):
    gene = tsv.split(".")[0]
    community = df0.loc[gene, "community"]
    lst.append([gene, community])
    tsv = f"gene_expression/{tsv}"
    df = pd.read_table(tsv, header=0, sep="\t")
    df = df.loc[1:, ["Sample", "TPM"]].set_index("Sample").rename(columns={"TPM": gene}).transpose() # tsv第二行没有数据
    dfs = pd.concat([dfs, df], axis=0)
    #break
pd.DataFrame(lst, columns=["gene", "community"]).to_csv("gene2community.tsv", header=True, index=False, sep="\t")
dfs.to_csv("gene_expression.tsv", header=True, index=True, sep="\t")
```

##### 绘制community分组和组织分组的热图

将指定组织分成多组，每组颜色域一样，其他组的组织颜色在该组设为white

```python
import pandas as pd
from more_itertools import chunked
df = pd.read_table("sample2tissue.tsv", header=0, sep="\t")
tissues = df["tissue"].drop_duplicates().tolist()
n = 0
for group in chunked(tissues, 9):
    n += 1
    df[f"group{n}"] = df["tissue"].apply(lambda tissue: tissue if tissue in group else "white")
    print(group)
    print(n)
df = df.drop(columns=["tissue"])
df.to_csv("grouped_tissue.tsv", header=True, index=False, sep="\t")
```

绘制分组热图

```R
library(pheatmap)
plot_heatmap <- function(df, df_row, df_col, color_list, tissue) {
    p <- pheatmap(df,
                # cellwidth=100, cellheight=18,
                fontsize=6, 
                # labels_col=groups,
                angle_col="90", 
                #cluster_cols = FALSE,
                cluster_rows = FALSE,
                show_rownames = FALSE,
                show_colnames = FALSE,
                border_color = "black",
                #display_number=T,
                color=colorRampPalette(c("#4576B4", "white", "#DA3428"))(50),
                # color=colorRampPalette(c("white", "#DA3428"))(50),
                main = tissue,
                annotation_row = df_row, 
                annotation_col = df_col,
                annotation_colors = color_list
                )
    return(p)
}
df_row <- read.table("gene2community.tsv", header=TRUE, sep="\t", row.names=1)
df_col <- read.table("grouped_tissue.tsv", header=TRUE, sep="\t", row.names=1)
genes <- rownames(df_row)[order(df_row$community)]
df0 <- read.table("sample2tissue.tsv", header=TRUE, sep="\t", row.names=1)
df <- read.table("gene_expression.tsv", header=TRUE, sep="\t", row.names=1)
df = df[genes, ]
df <- log10(df + 0.01)

color_list <- list()
colors <- c('white', '#e6194B', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#42d4f4', '#f032e6', '#fabed4')
for (group in colnames(df_col)) {
    tissues <- unique(df_col[group])
    names(colors) <- c("white", tissues[tissues!="white"])
    color_list[[group]] <- colors
}

tiff("gene_expression.heatmap.tiff", width=72, height=48, units="cm", res=600, compression="lzw")
plot_heatmap(df, df_row, df_col, color_list, "All")
dev.off()

# 按组织绘制
#tissues <- unique(df0$tissue)
#for (tissue in tissues) {
#    print(tissue)
#    samples <- rownames(df0)[which(df0$tissue==tissue)]
#    tiff(paste0("tissue_tiff/gene_expression.", tissue, ".tiff"), width=24, height=24, units="cm", res=600, compression="lzw")
#    try(plot_heatmap(df[, samples, drop=FALSE], df_row, tissue))
#    dev.off()
#}

# 指定组织绘制
#tissue <- "Mammary_L"
#samples <- rownames(df0)[which(df0$tissue==tissue)]
#print(samples)
#tiff(paste0("tissue_tiff/gene_expression.", tissue, ".tiff"), width=48, height=24, units="cm", res=600, compression="lzw")
#try(plot_heatmap(df[, samples, drop = FALSE], df_row, tissue))
#dev.off()
```

cattleGTEx的OR基因组织表达谱

![ngs.gene_expression.heatmap](0记录本/ngs.gene_expression.heatmap.png)

##### 其他

后续还做了TGS样本的类似结果，见目录：

```
/share/home/yzwl_zh/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx/cattle/cattle_tgsouy/penglingwei/OR/transcriptome/animalGTEx/cattle/cattle_tgs
```



### 20240202：（在做）

##### 原始材料

RNA-Seq数据为贝纳基因测序的多品种的肌肉样品

脚本由慧聪师兄直接提供

<img src="0记录本/image-20240202095641300.png" alt="image-20240202095641300" style="zoom: 25%;" />

依据download.sh下载参考数据和软件工具，对于Linux无法访问的github平台，在Windows上手动下载

创建conda环境

```
conda env create -f nf-farmgtex.yml
conda env create -f phaser.yml
```

问题

```
#1 nextflow.config报错，弃用nextflow.config，也不能让nextflow.config在当前目录
source /home/penglingwei/software/miniconda3/bin/activate nf-farmgtex
#nextflow run ./script/prepare.nf -c nextflow.config -resume -w ./work
nextflow run ./script/prepare.nf -resume -w ./work # nextflow.config
#2 更新过nextflow 
#3 更换对应版本的参数
gatk IndexFeatureFile -F ${params.vcf} => gatk IndexFeatureFile -I ${params.vcf}
#4 对fastq输入方式做了更改
#5 fastp更改版本为v0.23.4 (Fix a regression bug of FASTQ reader)
#6 生成start参考基因组索引
STAR  \
--runMode genomeGenerate \
--genomeDir indexstar \
--runThreadN 20 \
--genomeFastaFiles  Bos_taurus.ARS-UCD1.2.dna.toplevel.fa \
--sjdbGTFfile Bos_taurus.ARS-UCD1.2.108.chr.gtf \
--sjdbOverhang 149
参数说明：
# --runThreadN：线程数。
# --runMode genomeGenerate：构建基因组索引。
# --genomeDir：索引目录。（index_dir一定要是存在的文件夹，需提前建好）
# --genomeFastaFiles：基因组文件。
# --sjdbGTFfile：基因组注释文件。
# --sjdbOverhang：reads长度减1。
# 参考：https://www.jianshu.com/p/165a9b19545c
#7 生成salmon索引
# salmon index -p 40 -t Bos_taurus.ARS-UCD1.2.cdna.all.fa -i indexsalmon --keepDuplicates
# -t [ --transcripts ] arg Transcript fasta file.
# -i [ --index ] arg salmon index.
# -p [ --threads ] arg (=2) Number of threads to use during indexing.
#  --keepDuplicates keep duplicates transcript                     
#8
featureCounts工具(存在于GENE_feat和EXON)也要像fastp一样判定是否是双端测序，须保持同步更改
```



### 20240205：CORD网站爬虫

爬取OR基因的描述信息、DNA序列、蛋白序列

```
网站主页：https://cord.ihuman.shanghaitech.edu.cn/page/cord/index
```

##### step1：下载表格

在尝试爬虫，但是尚未实现，由小莲手动下载而得

##### step2：爬取序列

包括DNA序列和蛋白序列

```
import requests
import json
from fake_useragent import UserAgent 

headers = {
    'Accept': 'application/json, text/plain, */*',
    'Accept-Encoding': 'gzip, deflate, br',
    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
    'Authorization': 'Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJleHAiOjE3MDk1NDY0MjgsInVzZXJJZCI6InVzZXItaWQtYWJjIn0.YRil917BdWVHBp8fErj9VGLiCpYV4TSlzXymjEcj2o0r_acFiVQKvhOsFmuzTURw0PDOs2Is9j8nYwc5qOt1lA',
    'Connection': 'keep-alive',
    #'Cookie': 'JSESSIONID=370F12281332E4D9DB5CD2414D9A351E; KnowledgeGraphSearchHist=927885000915861504; ai_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJleHAiOjE3MDk1NDY0MjgsInVzZXJJZCI6InVzZXItaWQtYWJjIn0.YRil917BdWVHBp8fErj9VGLiCpYV4TSlzXymjEcj2o0r_acFiVQKvhOsFmuzTURw0PDOs2Is9j8nYwc5qOt1lA',
    'Host': 'cord.ihuman.shanghaitech.edu.cn',
    #'Referer': 'https://cord.ihuman.shanghaitech.edu.cn/page/cord/detail/MKOZDAF',
    'Sec-Fetch-Dest': 'empty',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Site': 'same-origin',
    #'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0',
    'User-Agent': UserAgent().random, 
    'sec-ch-ua': '"Not A(Brand";v="99", "Microsoft Edge";v="121", "Chromium";v="121"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Windows"'
} # Authorization是必须的


def getSequence(entry):
    url = f"https://cord.ihuman.shanghaitech.edu.cn/v2/graph/detail/sequence/{entry}?entry={entry}"
    response = requests.get(url, headers = headers).json()
    print(1)
    return {"dna": response["data"]["dnaSequence"], "protein": response["data"]["proteinSequence"]}
        
import os
import pandas as pd
from time import sleep
from random import random
for csv in os.listdir("ORgene_description"):
    species = csv.split(".")[0]
    entrys= pd.read_table(f"ORgene_description/{csv}", header=0, sep=",")["Entry"]
    #dna_fasta, protein_fasta = "dna_sequence/{species}.fasta", "protein_sequence/{species}.fasta"
    #os.system(f"> {dna_fasta} ; > {protein_fasta}")
    dna_fastas, protein_fastas = [], []
    n = 0
    for entry in entrys:
        n += 1
        print(n)
        sequence = getSequence(entry)
        dna, protein = sequence["dna"], sequence["protein"]
        dna_fastas.append(f">{entry}") ; dna_fastas.append(dna)
        protein_fastas.append(f">{entry}") ; protein_fastas.append(protein)
        sleep(random()/2)
    pd.Series(dna_fastas).to_csv(f"dna_sequence/{species}.fasta", header=False, index=False)
    pd.Series(protein_fastas).to_csv(f"protein_sequence/{species}.fasta", header=False, index=False)
    
    break
```



### 20240209：ACOX3相关代谢物分析

##### ACOX3

Acyl-Coenzyme A oxidase 3 also know as pristanoyl -CoA oxidase (ACOX3)is involved in the desaturation of 2-methyl branched fatty acids in peroxisomes. Unlike the rat homolog, the human gene is expressed in very low amounts in liver such that its mRNA was undetectable by routine Northern-blot analysis or its product by immunoblotting or by enzyme activity measurements. However the human cDNA encoding a 700 amino acid protein with a peroxisomal targeting C-terminal tripeptide S-K-L was isolated and is thought to be expressed under special conditions such as specific developmental stages or in a tissue specific manner in tissues that have not yet been examined. 

##### ACOX3在0,2,4,8天基因表达

| gene  | yd01  | yd02  | yd03  | yd21  | yd22  | yd23  | yd41 | yd42 | yd43 | yd81  | yd82  | yd83  |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ---- | ---- | ---- | ----- | ----- | ----- |
| ACOX3 | 19.88 | 21.35 | 18.84 | 12.75 | 13.18 | 13.48 | 8.71 | 8.59 | 7.82 | 11.29 | 11.83 | 17.88 |

##### ACOX3 KEGG相关代谢产物

bta01212: Fatty acid metabolism

```
Pathway网址：https://www.kegg.jp/pathway/map=bta01212&keyword=ACOX3
相关代谢物：
Entry Name Formula
C05270 Hexanoyl-CoA C27H46N7O17P3S
C05271 trans-Hex-2-enoyl-CoA C27H44N7O17P3S
C01944 Octanoyl-CoA C29H50N7O17P3S
C05276 trans-Oct-2-enoyl-CoA C29H48N7O17P3S
C05274 Decanoyl-CoA C31H54N7O17P3S
C05275 trans-Dec-2-enoyl-CoA C31H52N7O17P3S
C01832 Lauroyl-CoA C33H58N7O17P3S
C03221 2-trans-Dodecenoyl-CoA C33H56N7O17P3S
C02593 Tetradecanoyl-CoA C35H62N7O17P3S
C05273 trans-Tetradec-2-enoyl-CoA C35H60N7O17P3S
C00154 Palmitoyl-CoA C37H66N7O17P3S
C05272 trans-Hexadec-2-enoyl-CoA C37H64N7O17P3S
C16172 (6Z,9Z,12Z,15Z,18Z)-Tetracosapentaenoyl-CoA C45H72N7O17P3S
C16387 (2E,6Z,9Z,12Z,15Z,18Z)-Tetracosahexaenoyl-CoA C45H70N7O17P3S
C16168 (6Z,9Z,12Z,15Z,18Z,21Z)-Tetracosahexaenoyl-CoA C45H70N7O17P3S
C16374 (2E,6Z,9Z,12Z,15Z,18Z,21Z)-Tetracosaheptaenoyl-CoA C45H68N7O17P3S
# 查阅Entry: https://www.genome.jp/dbget-bin/www_bget?C05270
```

##### ACOX3皮尔逊相关系数最大代谢物

参考教程

```
https://blog.csdn.net/ziixiaoshenwang/article/details/115014316
```

```python
import pandas as pd
import numpy as np

df0 = pd.read_table("ACOX3.csv", header=0, sep=",", index_col=0) #基因
df = pd.read_table("metabolism_expression.csv", header=0, sep=",", index_col=0) #代谢物
# 计算平均值
df0["PA0"] = (df0["yd01"] + df0["yd02"] + df0["yd03"]) / 3
df0["DA2"] = (df0["yd21"] + df0["yd22"] + df0["yd23"]) / 3
df0["DA4"] = (df0["yd41"] + df0["yd42"] + df0["yd43"]) / 3
df0["DA8"] = (df0["yd81"] + df0["yd82"] + df0["yd83"]) / 3
ACOX3 = df0.loc["ACOX3", ["PA0", "DA2","DA4", "DA8"]].tolist()

df["PA0"] = (df["PA0-1"] + df["PA0-2"] + df["PA0-3"]) / 3
df["DA2"] = (df["DA2-1"] + df["DA2-2"] + df["DA2-3"]) / 3
df["DA4"] = (df["DA4-1"] + df["DA4-2"] + df["DA4-3"]) / 3
df["DA8"] = (df["DA8-1"] + df["DA8-2"] + df["DA8-3"]) / 3
df = df.drop(columns=["PA0-1", "PA0-2", "PA0-3", "DA2-1", "DA2-2", "DA2-3", "DA4-1", "DA4-2", "DA4-3", "DA8-1", "DA8-2", "DA8-3"])
def calculateCorrelation(metabolin):
    metabolins = df.loc[metabolin, ["PA0", "DA2","DA4", "DA8"]].tolist()
    correlation = np.corrcoef(ACOX3, metabolins)[0,1]
    return correlation

df["correlation"] = pd.Series(df.index).apply(lambda metabolin: calculateCorrelation(metabolin)).tolist() # 索引名！
df.to_csv("test.tsv", header=True, index=True, sep="\t")

# "C:\Users\Peng Lingwei\文件\个人文件夹\课题\group\unclassified\ACOX3.csv"
```



### 20240219：荷斯坦牛IGFBP7基因第一内含子序列

(/home/penglingwei/group/zhangxiang/IGFBP7/intron_sequence)

##### step1：提取海福特牛IGFBP7基因的exon1+intron1+exon2序列

##### step2：比对荷斯坦牛参考基因组

```shell
minimap2 -ax asm5 ref.fa asm.fa > aln.sam # assembly to assembly/ref alignment
```

##### step3：sam转换为bed格式

便于获得在荷斯坦牛参考基因组的坐标

```shell
bedtools bamtobed -i aln.sam > aln.bed
```

##### step4：提取荷斯坦牛的exon1+intron1+exon2序列

借助NCBI数据库

##### step5：剔除exon1和exon2序列



### 20240224：安格斯牛和荷斯坦牛脂肪组织IGFBP7基因表达

(/home/penglingwei/group/zhangxiang/IGFBP7/adipose_expression)

##### step1：CattleGTEx手动下载IGFBP7数据

##### step2：确定Angus和Holstein的样本号

```shell
> output/IGFBP7_expression.plot.tsv
cat input/adipse_sample.tsv | while IFS=$'\t' read sample breed
do
tpm=`awk -v sample=${sample} '$3==sample {print $2}' input/IGFBP7_expression.tsv`
echo -e "${sample}\t${breed}\t${tpm}" >> output/IGFBP7_expression.plot.tsv
done
```

##### step3：绘制小提琴图和箱线图

```R
library(ggplot2)
library(patchwork)
df <- read.table("output/IGFBP7_expression.plot.tsv", header=F, sep="\t")
colnames(df) <- c("Sample", "Breed", "Tpm")
# violin
p <- ggplot(df, aes(y=Tpm, x=Breed, fill=Breed)) + geom_violin()
p <- p + ylab("TPM")
p <- p + scale_fill_manual(
        values = c(Angus="#1F77B4", Holstein="#2CA02C"),
        breaks = c("Angus", "Holstein"))
p <- p + scale_y_continuous()
p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
p <- p + theme(axis.title.x = element_blank(), axis.text.x=element_text(size=12, color="black"), axis.text.y=element_text(size=12, color="black"))
p1 <- p + guides(fill = "none",color ="none",shape ="none")
# boxplot
p <- ggplot(df, aes(y=Tpm, x=Breed, fill=Breed)) + stat_boxplot(geom='errorbar', width=0.2) + geom_boxplot(width=0.5, outlier.color="white") 
p <- p + ylab("TPM")
p <- p + scale_fill_manual(
        values = c(Angus="#1F77B4", Holstein="#2CA02C"),
        breaks = c("Angus", "Holstein"))
p <- p + scale_y_continuous(limits=c(0, 450))
p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
p <- p + theme(axis.title.x = element_blank(), axis.text.x=element_text(size=12, color="black"), axis.text.y=element_text(size=12, color="black"))
p2 <- p + guides(fill = "none",color ="none",shape ="none")
tiff("output/IGFBP7_expression.plot.tiff", width=16, height=8, units="cm", res=600, compression="lzw")
p1 | p2
dev.off()
```

<img src="0记录本/image-20240224184417193.png" alt="image-20240224184417193" style="zoom:30%;" />



### 20240226：WGCNA分析和共表达网络图绘制

(/home/penglingwei/group/zhangxiang/IGFBP7/WGCNA)

##### step1：WGCNA分析区分模块基因

```R
# https://github.com/jmzeng1314/my_WGCNA 参照jmzeng1314给出的教程，非常完善！

rm(list = ls())
options(stringsAsFactors = F)

# 切换工作目录如果有必要的话
# setwd('WGCNA/')
# 	56 breast cancer cell lines were profiled to identify patterns of gene expression associated with subtype and response to therapeutic compounds.
# 这个时候需要制作表达矩阵，每个实例都不一样，代码需要灵活调整
# 我已经制作好了 GSE48213-wgcna-input.RData ，大家直接运行后面的WGCNA代码即可。
if(F){
  ## https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE48213
  #wget -c ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE48nnn/GSE48213/suppl/GSE48213_RAW.tar
  #tar -xf GSE48213_RAW.tar
  #gzip -d *.gz
  ## 首先在GSE48213_RAW目录里面生成tmp.txt文件，使用shell脚本
  # awk '{print FILENAME"\t"$0}' GSM*.txt |grep -v EnsEMBL_Gene_ID >tmp.txt
  #  其实也可以直接使用R来读取GSE48213_RAW.tar里面的gz文件，这里就不演示了
  # 可以参考：https://mp.weixin.qq.com/s/OLc9QmfN0YcT548VAYgOPA 里面的教程
  ## 然后把tmp.txt导入R语言里面用reshape2处理即可
  # 这个 tmp.txt 文件应该是100M左右大小哦。
  a=read.table('GSE48213_RAW/tmp.txt',sep = '\t',stringsAsFactors = F)
  library(reshape2)
  fpkm <- dcast(a,formula = V2~V1)
  rownames(fpkm)=fpkm[,1]
  fpkm=fpkm[,-1]
  colnames(fpkm)=sapply(colnames(fpkm),function(x) strsplit(x,"_")[[1]][1])
  
  
  
  library(GEOquery)
  a=getGEO('GSE48213')
  metadata=pData(a[[1]])[,c(2,10,12)]
  datTraits = data.frame(gsm=metadata[,1],
             cellline=trimws(sapply(as.character(metadata$characteristics_ch1),function(x) strsplit(x,":")[[1]][2])),
             subtype=trimws(sapply(as.character(metadata$characteristics_ch1.2),function(x) strsplit(x,":")[[1]][2]))
             )
  save(fpkm,datTraits,file = 'GSE48213-wgcna-input.RData')
}
load('GSE48213-wgcna-input.RData')
library(WGCNA)
## step 1 :
if(T){
  
  fpkm[1:4,1:4]
  head(datTraits)
  table(datTraits$subtype)
  RNAseq_voom <- fpkm 
  ## 因为WGCNA针对的是基因进行聚类，而一般我们的聚类是针对样本用hclust即可，所以这个时候需要转置
  WGCNA_matrix = t(RNAseq_voom[order(apply(RNAseq_voom,1,mad), decreasing = T)[1:5000],])
  datExpr0 <- WGCNA_matrix  ## top 5000 mad genes
  datExpr <- datExpr0 
  
  ## 下面主要是为了防止临床表型与样本名字对不上
  sampleNames = rownames(datExpr);
  traitRows = match(sampleNames, datTraits$gsm)
  rownames(datTraits) = datTraits[traitRows, 1]
  
}


## step 2 
datExpr[1:4,1:4]
if(T){
  powers = c(c(1:10), seq(from = 12, to=20, by=2))
  # Call the network topology analysis function
  sft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)
  #设置网络构建参数选择范围，计算无尺度分布拓扑矩阵
  png("step2-beta-value.png",width = 800,height = 600)
  # Plot the results:
  ##sizeGrWindow(9, 5)
  par(mfrow = c(1,2));
  cex1 = 0.9;
  # Scale-free topology fit index as a function of the soft-thresholding power
  plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
       xlab="Soft Threshold (power)",ylab="Scale Free Topology Model Fit,signed R^2",type="n",
       main = paste("Scale independence"));
  text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
       labels=powers,cex=cex1,col="red");
  # this line corresponds to using an R^2 cut-off of h
  abline(h=0.90,col="red")
  # Mean connectivity as a function of the soft-thresholding power
  plot(sft$fitIndices[,1], sft$fitIndices[,5],
       xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",
       main = paste("Mean connectivity"))
  text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")
  dev.off()
}

## step3 构建加权共表达网络（Weight co-expression network)
## 首先是一步法完成网络构建
if(T){
  net = blockwiseModules(
    datExpr,
    power = sft$powerEstimate,
    maxBlockSize = 6000,
    TOMType = "unsigned", minModuleSize = 30,
    reassignThreshold = 0, mergeCutHeight = 0.25,
    numericLabels = TRUE, pamRespectsDendro = FALSE,
    saveTOMs = F, 
    verbose = 3
  )
  table(net$colors) 
}
## 然后是分布法完成网络构建，仅供有探索精神的同学挑战。

## 构建加权共表达网络分为两步：
## 1. 计算邻近值，也是就是两个基因在不样品中表达量的表达相关系数(pearson correlation rho)，
## 参考 2.b.2 in https://labs.genetics.ucla.edu/horvath/htdocs/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/FemaleLiver-02-networkConstr-man.pdf
## 2. 计算topology overlap similarity (TOM)。 WGCNA认为，只通过计算两个基因的表达相关系数构建共表达网络是不足够的。
## 于是他们用TOM表示两个基因在网络结构上的相似性，即两个基因如果具有相似的邻近基因，这两个基因更倾向于有相互作用。
## 参考 2.b.3 in https://labs.genetics.ucla.edu/horvath/htdocs/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/FemaleLiver-02-networkConstr-man.pdf


if(F){
	#(1)网络构建 Co-expression similarity and adjacency 
	adjacency = adjacency(datExpr, power = sft$powerEstimate) 
	#(2) 邻近矩阵到拓扑矩阵的转换，Turn adjacency into topological overlap
	TOM = TOMsimilarity(adjacency);
	dissTOM = 1-TOM
	# (3) 聚类拓扑矩阵 Call the hierarchical clustering function
	geneTree = hclust(as.dist(dissTOM), method = "average");
	# Plot the resulting clustering tree (dendrogram)
	sizeGrWindow(12,9)
	## 这个时候的geneTree与一步法的 net$dendrograms[[1]] 性质类似，但是还需要进行进一步处理
	plot(geneTree, xlab="", sub="", main = "Gene clustering on TOM-based dissimilarity",
		 labels = FALSE, hang = 0.04);
	#(4) 聚类分支的修整 dynamicTreeCut 
	# We like large modules, so we set the minimum module size relatively high:
	minModuleSize = 30;
	# Module identification using dynamic tree cut:
	dynamicMods = cutreeDynamic(dendro = geneTree, distM = dissTOM,
								deepSplit = 2, pamRespectsDendro = FALSE,
								minClusterSize = minModuleSize);
	table(dynamicMods)
	#4. 绘画结果展示
	# Convert numeric lables into colors
	dynamicColors = labels2colors(dynamicMods)
	table(dynamicColors)
	# Plot the dendrogram and colors underneath
	#sizeGrWindow(8,6)
	plotDendroAndColors(geneTree, dynamicColors, "Dynamic Tree Cut",
						dendroLabels = FALSE, hang = 0.03,
						addGuide = TRUE, guideHang = 0.05,
						main = "Gene dendrogram and module colors")
	#5. 聚类结果相似模块的融合，Merging of modules whose expression profiles are very similar
	#在聚类树中每一leaf是一个短线，代表一个基因，
	#不同分之间靠的越近表示有高的共表达基因，将共表达极其相似的modules进行融合
	# Calculate eigengenes
	MEList = moduleEigengenes(datExpr, colors = dynamicColors)
	MEs = MEList$eigengenes
	# Calculate dissimilarity of module eigengenes
	MEDiss = 1-cor(MEs);
	# Cluster module eigengenes
	METree = hclust(as.dist(MEDiss), method = "average");
	# Plot the result
	#sizeGrWindow(7, 6)
	plot(METree, main = "Clustering of module eigengenes",
		 xlab = "", sub = "")
	#选择有75%相关性的进行融合
	MEDissThres = 0.25
	# Plot the cut line into the dendrogram
	abline(h=MEDissThres, col = "red")
	# Call an automatic merging function
	merge = mergeCloseModules(datExpr, dynamicColors, cutHeight = MEDissThres, verbose = 3)
	# The merged module colors
	mergedColors = merge$colors;
	# Eigengenes of the new merged modules:
	mergedMEs = merge$newMEs
	
}

## step 4 ： 模块可视化
if(T){
  
  # Convert labels to colors for plotting
  mergedColors = labels2colors(net$colors)
  table(mergedColors)
  moduleColors=mergedColors
  # Plot the dendrogram and the module colors underneath
  png("step4-genes-modules.png",width = 800,height = 600)
  plotDendroAndColors(net$dendrograms[[1]], mergedColors[net$blockGenes[[1]]],
                      "Module colors",
                      dendroLabels = FALSE, hang = 0.03,
                      addGuide = TRUE, guideHang = 0.05)
  dev.off()
  ## assign all of the gene to their corresponding module 
  ## hclust for the genes.
}

if(F){
  #明确样本数和基因
  nGenes = ncol(datExpr)
  nSamples = nrow(datExpr)
  #首先针对样本做个系统聚类
  datExpr_tree<-hclust(dist(datExpr), method = "average")
  par(mar = c(0,5,2,0))
  plot(datExpr_tree, main = "Sample clustering", sub="", xlab="", cex.lab = 2, 
       cex.axis = 1, cex.main = 1,cex.lab=1)
  ## 如果这个时候样本是有性状，或者临床表型的，可以加进去看看是否聚类合理
  #针对前面构造的样品矩阵添加对应颜色
  sample_colors <- numbers2colors(as.numeric(factor(datTraits$subtype)), 
                                  colors = c("white","blue","red","green"),signed = FALSE)
  ## 这个给样品添加对应颜色的代码需要自行修改以适应自己的数据分析项目
  #  sample_colors <- numbers2colors( datTraits ,signed = FALSE)
  ## 如果样品有多种分类情况，而且 datTraits 里面都是分类信息，那么可以直接用上面代码，当然，这样给的颜色不明显，意义不大
  #10个样品的系统聚类树及性状热图
  par(mar = c(1,4,3,1),cex=0.8)
  
  png("sample-subtype-cluster.png",width = 800,height = 600)
  plotDendroAndColors(datExpr_tree, sample_colors,
                      groupLabels = colnames(sample),
                      cex.dendroLabels = 0.8,
                      marAll = c(1, 4, 3, 1),
                      cex.rowText = 0.01,
                      main = "Sample dendrogram and trait heatmap")
  dev.off()
}

## step 5 (最重要的) 模块和性状的关系
## 这一步主要是针对于连续变量，如果是分类变量，需要转换成连续变量方可使用
table(datTraits$subtype)
if(T){
  nGenes = ncol(datExpr)
  nSamples = nrow(datExpr)
  design=model.matrix(~0+ datTraits$subtype)
  colnames(design)=levels(datTraits$subtype)
  moduleColors <- labels2colors(net$colors)
  # Recalculate MEs with color labels
  MEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenes
  MEs = orderMEs(MEs0); ##不同颜色的模块的ME值矩 (样本vs模块)
  moduleTraitCor = cor(MEs, design , use = "p");
  moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)
  
  sizeGrWindow(10,6)
  # Will display correlations and their p-values
  textMatrix = paste(signif(moduleTraitCor, 2), "\n(",
                     signif(moduleTraitPvalue, 1), ")", sep = "");
  dim(textMatrix) = dim(moduleTraitCor)
  png("step5-Module-trait-relationships.png",width = 800,height = 1200,res = 120)
  par(mar = c(6, 8.5, 3, 3));
  # Display the correlation values within a heatmap plot
  labeledHeatmap(Matrix = moduleTraitCor,
                 xLabels = colnames(design),
                 yLabels = names(MEs),
                 ySymbols = names(MEs),
                 colorLabels = FALSE,
                 colors = greenWhiteRed(50),
                 textMatrix = textMatrix,
                 setStdMargins = FALSE,
                 cex.text = 0.5,
                 zlim = c(-1,1),
                 main = paste("Module-trait relationships"))
  dev.off()
  
  # 除了上面的热图展现形状与基因模块的相关性外
  # 还可以是条形图,但是只能是指定某个形状
  # 或者自己循环一下批量出图。
  Luminal = as.data.frame(design[,3]);
  names(Luminal) = "Luminal"
  y=Luminal
  GS1=as.numeric(cor(y,datExpr, use="p"))
  GeneSignificance=abs(GS1)
  # Next module significance is defined as average gene significance.
  ModuleSignificance=tapply(GeneSignificance,
                            moduleColors, mean, na.rm=T)
  sizeGrWindow(8,7)
  par(mfrow = c(1,1))
  # 如果模块太多，下面的展示就不友好
  # 不过，我们可以自定义出图。
  plotModuleSignificance(GeneSignificance,moduleColors)
  
}


## step 6 (第二重要的)：感兴趣性状的模块的具体基因分析
# 查看第五步出图：step5-Module-trait-relationships.png
# 发现跟 Luminal 亚型 最相关的是  brown 模块
# 所以接下来就分析这两个
Luminal = as.data.frame(design[,3]);
names(Luminal) = "Luminal"
module = "brown"
if(T){
  # names (colors) of the modules
  modNames = substring(names(MEs), 3)
  geneModuleMembership = as.data.frame(cor(datExpr, MEs, use = "p"));
  ## 算出每个模块跟基因的皮尔森相关系数矩
  ## MEs是每个模块在每个样本里面的
  ## datExpr是每个基因在每个样本的表达量
  MMPvalue = as.data.frame(corPvalueStudent(as.matrix(geneModuleMembership), nSamples));
  names(geneModuleMembership) = paste("MM", modNames, sep="");
  names(MMPvalue) = paste("p.MM", modNames, sep="");
  geneModuleMembership[1:4,1:4]
  
  
  ## 只有连续型性状才能只有计算
  ## 这里把是否属 Luminal 表型这个变量0,1进行数值化
  Luminal = as.data.frame(design[,3]);
  names(Luminal) = "Luminal"
  geneTraitSignificance = as.data.frame(cor(datExpr, Luminal, use = "p"));
  GSPvalue = as.data.frame(corPvalueStudent(as.matrix(geneTraitSignificance), nSamples));
  names(geneTraitSignificance) = paste("GS.", names(Luminal), sep="");
  names(GSPvalue) = paste("p.GS.", names(Luminal), sep="");
  
  module = "brown"
  column = match(module, modNames);
  moduleGenes = moduleColors==module;
  png("step6-Module_membership-gene_significance.png",width = 800,height = 600)
  #sizeGrWindow(7, 7);
  par(mfrow = c(1,1));
  verboseScatterplot(abs(geneModuleMembership[moduleGenes, column]),
                     abs(geneTraitSignificance[moduleGenes, 1]),
                     xlab = paste("Module Membership in", module, "module"),
                     ylab = "Gene significance for Luminal",
                     main = paste("Module membership vs. gene significance\n"),
                     cex.main = 1.2, cex.lab = 1.2, cex.axis = 1.2, col = module)
  dev.off()
  
}


## step 7 
# 主要是可视化 TOM矩阵，WGCNA的标准配图
# 然后可视化不同 模块 的相关性 热图
# 不同模块的层次聚类图
# 还有模块诊断，主要是 intramodular connectivity
if(T){
  nGenes = ncol(datExpr)
  nSamples = nrow(datExpr)
  geneTree = net$dendrograms[[1]]; 
  dissTOM = 1-TOMsimilarityFromExpr(datExpr, power = 6); 
  plotTOM = dissTOM^7; 
  diag(plotTOM) = NA; 
  #TOMplot(plotTOM, geneTree, moduleColors, main = "Network heatmap plot, all genes")
  nSelect = 400
  # For reproducibility, we set the random seed
  set.seed(10);
  select = sample(nGenes, size = nSelect);
  selectTOM = dissTOM[select, select];
  # There’s no simple way of restricting a clustering tree to a subset of genes, so we must re-cluster.
  selectTree = hclust(as.dist(selectTOM), method = "average")
  selectColors = moduleColors[select];
  # Open a graphical window
  sizeGrWindow(9,9)
  # Taking the dissimilarity to a power, say 10, makes the plot more informative by effectively changing
  # the color palette; setting the diagonal to NA also improves the clarity of the plot
  plotDiss = selectTOM^7;
  diag(plotDiss) = NA;
  
  png("step7-Network-heatmap.png",width = 800,height = 600)
  TOMplot(plotDiss, selectTree, selectColors, main = "Network heatmap plot, selected genes")
  dev.off()
  
  # Recalculate module eigengenes
  MEs = moduleEigengenes(datExpr, moduleColors)$eigengenes
  ## 只有连续型性状才能只有计算
  ## 这里把是否属 Luminal 表型这个变量0,1进行数值化
  Luminal = as.data.frame(design[,3]);
  names(Luminal) = "Luminal"
  # Add the weight to existing module eigengenes
  MET = orderMEs(cbind(MEs, Luminal))
  # Plot the relationships among the eigengenes and the trait
  sizeGrWindow(5,7.5);
  
  par(cex = 0.9)
  png("step7-Eigengene-dendrogram.png",width = 800,height = 600)
  plotEigengeneNetworks(MET, "", marDendro = c(0,4,1,2), marHeatmap = c(3,4,1,2), cex.lab = 0.8, xLabelsAngle
                        = 90)
  dev.off()
  
  # Plot the dendrogram
  sizeGrWindow(6,6);
  par(cex = 1.0)
  ## 模块的进化树
  png("step7-Eigengene-dendrogram-hclust.png",width = 800,height = 600)
  plotEigengeneNetworks(MET, "Eigengene dendrogram", marDendro = c(0,4,2,0),
                        plotHeatmaps = FALSE)
  dev.off()
  # Plot the heatmap matrix (note: this plot will overwrite the dendrogram plot)
  par(cex = 1.0)
  ## 性状与模块热
  
  png("step7-Eigengene-adjacency-heatmap.png",width = 800,height = 600)
  plotEigengeneNetworks(MET, "Eigengene adjacency heatmap", marHeatmap = c(3,4,2,2),
                        plotDendrograms = FALSE, xLabelsAngle = 90)
  dev.off()
  
}

## step 8 
# 主要是关心具体某个模块内部的基因
if(T){
  # Select module
  module = "brown";
  # Select module probes
  probes = colnames(datExpr) ## 我们例子里面的probe就是基因
  inModule = (moduleColors==module);
  modProbes = probes[inModule]; 
  head(modProbes)
  
  # 如果使用WGCNA包自带的热图就很丑。
  which.module="brown";
  dat=datExpr[,moduleColors==which.module ] 
  plotMat(t(scale(dat)),nrgcols=30,rlabels=T,
          clabels=T,rcols=which.module,
          title=which.module )
  datExpr[1:4,1:4]
  dat=t(datExpr[,moduleColors==which.module ] )
  library(pheatmap)
  pheatmap(dat ,show_colnames =F,show_rownames = F) #对那些提取出来的1000个基因所在的每一行取出，组合起来为一个新的表达矩阵
  n=t(scale(t(log(dat+1)))) # 'scale'可以对log-ratio数值进行归一化
  n[n>2]=2 
  n[n< -2]= -2
  n[1:4,1:4]
  pheatmap(n,show_colnames =F,show_rownames = F)
  group_list=datTraits$subtype
  ac=data.frame(g=group_list)
  rownames(ac)=colnames(n) 
  pheatmap(n,show_colnames =F,show_rownames = F,
           annotation_col=ac )
  # 可以很清晰的看到，所有的形状相关的模块基因
  # 其实未必就不是差异表达基因。
}

## step 9 
# 导出模块内部基因的连接关系，进入其它可视化软件
# 比如 cytoscape软件等等。
if(T){
  # Recalculate topological overlap
  TOM = TOMsimilarityFromExpr(datExpr, power = sft$powerEstimate); 
  # Select module
  module = "brown";
  # Select module probes
  probes = colnames(datExpr) ## 我们例子里面的probe就是基因
  inModule = (moduleColors==module);
  modProbes = probes[inModule]; 
  ## 也是提取指定模块的基因名
  # Select the corresponding Topological Overlap
  modTOM = TOM[inModule, inModule];
  dimnames(modTOM) = list(modProbes, modProbes)
  ## 模块对应的基因关系矩
  cyt = exportNetworkToCytoscape(
    modTOM,
    edgeFile = paste("CytoscapeInput-edges-", paste(module, collapse="-"), ".txt", sep=""),
    nodeFile = paste("CytoscapeInput-nodes-", paste(module, collapse="-"), ".txt", sep=""),
    weighted = TRUE,
    threshold = 0.02,
    nodeNames = modProbes, 
    nodeAttr = moduleColors[inModule]
  );
}
```

##### step2：筛选IGFBP7相关的网络连接

根据weight筛选选top行

```python
import pandas as pd
df = pd.read_table("CytoscapeInput-edges-yellow.txt", header=0, sep="\t")
# step1
q = df["weight"].quantile(0.8)
df = df[df["weight"] > q] # top20% #!!!
# step2
adjacent_genes = ["ENSBTAG00000019368"] + df.loc[df["fromNode"]=="ENSBTAG00000019368", "toNode"].tolist() + df.loc[df["toNode"]=="ENSBTAG00000019368", "fromNode"].tolist()
df = df[(df["fromNode"].isin(adjacent_genes)) & (df["toNode"].isin(adjacent_genes))]
# step3
gene2name = {}
df["fromNode"] = df["fromNode"].apply(lambda x: gene2name[x])
df["toNode"] = df["toNode"].apply(lambda x: gene2name[x])
df.to_csv("CytoscapeInput-edges-yellow.filter.txt", header=True, index=False, sep="\t")
```



### 20240226：荷斯坦牛IGFBP7基因的位置

```
hereford_genome=/home/penglingwei/pan_transcriptome/ref/genome_fa/other/GCF_002263795.2_ARS-UCD1.3_genomic.fna
holstein_genome=/home/penglingwei/pan_transcriptome/ref/genome_fa/GCA_021347905.1_ARS-LIC_NZ_Holstein-Friesian_1_genomic.fna
# step1：定位IGFBP7基因在荷斯坦奶牛位置
samtools faidx ${hereford_genome} NC_037333.1:72405517-72485427 --reverse-complement > IGFBP7_gene.fasta
minimap2 -t 10 -ax asm5 ${holstein_genome} IGFBP7_gene.fasta > aln.sam
bedtools bamtobed -i aln.sam > aln.bed
# step2：用于核验首位位置
samtools faidx ${hereford_genome} NC_037333.1:72484919-72485427 --reverse-complement > exon1.fasta
samtools faidx ${hereford_genome} NC_037333.1:72405517-72405778 --reverse-complement > exon5.fasta
# step3：最终结果
echo CM038084.1:72360496-72438224
```



```
import pandas as pd
import re
import os

def extractChromosomeSequence(coordinate): # 从ARS-UCD提取序列
    genome_fasta = "/home/penglingwei/pan_transcriptome/ref/genome_fa/other/GCF_002263795.2_ARS-UCD1.3_genomic.fna"
    samtools = "/home/penglingwei/software/miniconda3/bin/samtools"
    chromosome, start, end, strand = coordinate[0], coordinate[1], coordinate[2], coordinate[3]
    if strand == "+":
        with os.popen(f"{samtools} faidx {genome_fasta} {chromosome}:{start}-{end} 2> /dev/null") as fasta:
            return "".join(fasta.read().split("\n")[1: ]).upper() # 去除输出fasta自带的序列名
    if strand == "-":
        with os.popen(f"{samtools} faidx {genome_fasta} {chromosome}:{start}-{end} --reverse-complement 2> /dev/null") as fasta:
            return "".join(fasta.read().split("\n")[1: ]).upper()


df = pd.read_table("test.sam", header=None, sep="\t", comment="@")
chr, pos, cigar, seq = df.loc[0, [2, 3, 5, 9]].tolist()

ref_pos, qry_pos = pos, 1
numbers = [int(x) for x in re.findall(r'\d+', cigar)]
letters = re.findall(r'[A-Za-z]', cigar)

ref_seq, qry_seq = "", ""
for number, letter in zip(numbers, letters):
    if letter == "M":
        start = qry_pos
        ref_pos += number
        qry_pos += number

        end = qry_pos
        match_seq = seq[start: end] # start，end为1-based的左闭右开 
        ref_seq += match_seq
        qry_seq += match_seq 

    if letter == "D":
        start = ref_pos 
        ref_pos += number
        qry_pos += 1

        end = ref_pos - 1
        delete_seq = extractChromosomeSequence([chr, start, end, "+"])
        ref_seq += delete_seq
        qry_seq += "-" * number

    if letter == "I":
        start = qry_pos
        ref_pos += 1
        qry_pos += number

        end = qry_pos
        insert_seq = seq[start: end]
        ref_seq += "-" * number
        qry_seq += insert_seq

with open("tmp", "w") as f:
    f.write(f"{ref_seq}\n{qry_seq}")


https://zhuanlan.zhihu.com/p/158719525
```



### 20240301：下载长读长转录组测序数据

（/share/home/yzwl_zhouy/penglingwei/OR/raw/TGS/penglingwei）

##### step1：NCBI高级搜索指定平台的转录组测序

```
搜索网址：https://www.ncbi.nlm.nih.gov/sra
搜索框键入：("oxford nanopore"[Platform] OR "pacbio smrt"[Platform]) AND ("transcriptomic"[Source] OR "rna seq"[Strategy]) 
```

```
"oxford nanopore"[Platform] AND ("transcriptomic"[Source] OR "rna seq"[Strategy]) => 78896
"pacbio smrt"[Platform] AND ("transcriptomic"[Source] OR "rna seq"[Strategy]) => 11612
```



##### step2：下载检索结果

```
Send to => File => Summary => Create File
```

下载的结果以Experiment Accession为行标识，而Experiment Accession可能会对应多个Sample Accession

##### step3：筛选指定结果

对metadata去冗余，筛选指定物种

```python
import pandas as pd
df = pd.read_table("input/sra_result.csv", header=0, sep=",")
df = df.drop_duplicates("Sample Accession") # 避免多个实验用到同一个样本的情况
df.to_csv("output/sra_result.all_species.csv", header=True, index=False, sep="\t")

# 脊索动物门的物种
Chordata_species = pd.read_table("output/manual_execute/species.Chordata.txt", header=None, sep="\t").loc[:, 0].tolist()
#print(pd.read_table("output/manual_execute/species.Chordata.txt", header=None, sep="\t"))
#print(Chordata_species)
df = df[df["Organism Name"].isin(Chordata_species)]
df.to_csv("output/sra_result.Chordata.tsv", header=True, index=False, sep="\t")

# 代老师拟采用的物种
df0 = pd.read_table("input/species_list.txt", header=None, sep="\t", index_col=4)
species = df0.index.tolist()
df = df[df["Organism Name"].isin(species)]
species2number = df["Organism Name"].value_counts()
pd.DataFrame(
    [[species, df0.loc[species, 7], species2number[species]] for species in species2number.index],
    columns=["species", "name", "number"]).to_csv("output/species_number.tsv", header=True, index=False, sep="\t")
df.to_csv("output/sra_result.selected_species.tsv", header=True, index=False, sep="\t")
```

获取物种谱系，获得来自脊索动物门的物种

```shell
execute() {
  species=$1
  taxid=`echo "${species}" | taxonkit name2taxid | cut -f 2`
  lineage=`echo ${taxid} | taxonkit lineage | taxonkit reformat | cut -f 3`
  Phylum=`echo "${lineage}" | cut -d ";" -f 2`
  if [[ "${Phylum}" = "Chordata" ]] ; then
    echo -e "${species}\t${taxid}\t${lineage}" > output/manual_execute/lineage/${taxid}.txt
  fi
}
export -f execute

cat output/manual_execute/species.txt | while IFS= read -r species
do
  csub -J plw -q fat4 -o tmp.out -e tmp.err -n 1 -R span[hosts=1] "execute \"${species}\""
done
```



### 20230305：长读长转录组数据中脊索动物门中物种OR基因表达

/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS
├── step0_data
│   ├── raw
│   └── ref
├── step1_filter
│   ├── 01.filter.sh
│   ├── filter
│   ├── log
│   └── sample2raw_fq.tsv
├── step2_mapping
│   ├── 01_long_read.sh
│   ├── 01.mapping.sh
│   ├── end_record.txt
│   ├── log
│   ├── mapping
│   ├── sample2filter_fq.tsv
│   ├── start_record.txt
│   └── test.sh
├── step3_quant
│   ├── 01_long_read.sh
│   ├── 01.quant.sh
│   ├── log
│   ├── quant
│   ├── sample2bam.tsv
│   └── sample2bam.tsvs
└── step4_ORexpression
    ├── 01.ensembl_OR.sh
    ├── 02.cbind_expresiong.py
    ├── input
    ├── log
    ├── sample.tsv
    ├── step1_OR_sequence
    ├── step2_mapping
    ├── step3_sam2gtf
    ├── step4_gffcompare
    └── step5_expression_matrix

##### step1：下载原始数据和参考文件

raw
├── 01.process_metadata.py
├── 01.taxonkit.sh
├── 02.download_fastq.sh
├── 02.submit_download.sh
├── input
├── log
├── output
├── part1.experiment_accession.txt
├── part1.log
├── part1.species_number.tsv
├── raw
└── test.sh

```python
# 01.process_metadata.py
import pandas as pd
df = pd.read_table("input/sra_result.csv", header=0, sep=",")
#xxxdf = df.drop_duplicates("Sample Accession") # 避免多个实验用到同一个样本的情况,理解有误
#xxxdf.to_csv("output/sra_result.all_species.csv", header=True, index=False, sep="\t")

# 脊索动物门的物种
print("错位运行代码以获得用于筛选的脊索动物门物种list")
Chordata_species = pd.read_table("output/manual_execute/species.Chordata.txt", header=None, sep="\t").loc[:, 0].tolist()
df = df[df["Organism Name"].isin(Chordata_species)]
df.to_csv("output/sra_result.Chordata.tsv", header=True, index=False, sep="\t")

# 代老师拟采用的物种
df0 = pd.read_table("input/species_list.txt", header=None, sep="\t", index_col=4)
species = df0.index.tolist()
df = df[df["Organism Name"].isin(species)]
species2number = df["Organism Name"].value_counts()
pd.DataFrame(
    [[species, df0.loc[species, 7], species2number[species]] for species in species2number.index],
    columns=["species", "name", "number"]).to_csv("output/species_number.tsv", header=True, index=False, sep="\t")
df.to_csv("output/sra_result.selected_species.tsv", header=True, index=False, sep="\t")
```

```shell
# 01.taxonkit.sh
execute() {
  species=$1
  taxid=`echo "${species}" | taxonkit name2taxid | cut -f 2`
  lineage=`echo ${taxid} | taxonkit lineage | taxonkit reformat | cut -f 3`
  Phylum=`echo "${lineage}" | cut -d ";" -f 2`
  if [[ "${Phylum}" = "Chordata" ]] ; then
    echo -e "${species}\t${taxid}\t${lineage}" > output/manual_execute/lineage/${taxid}.txt
  fi
}
export -f execute

cat output/manual_execute/species.txt | while IFS= read -r species
do
  csub -J plw -q fat4 -o tmp.out -e tmp.err -n 1 -R span[hosts=1] "execute \"${species}\""
done
```

```shell
# step0_data/raw/02.download_fastq.sh 
# input
experiment_accession=$1 ; wd=raw
keyfile=/share/home/yzwl_zhouy/software/aspera-3.7.4/etc/asperaweb_id_dsa.openssh

# output
outfolder=${wd}/${experiment_accession} ; mkdir -p ${outfolder}
tsv=${outfolder}/${experiment_accession}.tsv
url="https://www.ebi.ac.uk/ena/portal/api/filereport?accession=${experiment_accession}&result=read_run&fields=run_accession,fastq_md5,fastq_aspera&format=tsv&download=true&limit=0"

echo "=>=>=>${experiment_accession}"
date

echo ">>>step1：从ebi中下载${experiment_accession}的详细信息" 
wget -c ${url} -O ${tsv} 
if [ -s "${tsv}" ] ; then 
  status=1 
else
  echo ">>>无法获得ebi中${experiment_accession}的样本信息" 
  status=0
fi

echo ">>>step2：检测fastq_aspera是否有效" 
if [ "${status}" == 1 ] ; then
  read -r run fastq_md5 fastq_aspera <<< `awk 'NR==2' ${tsv}`
  num=0
  if [ "${fastq_aspera}" == "" ] ; then echo ">>>fastq_aspera无效" ; status=0 ; fi
fi

if [ "${status}" == 1 ] ; then
  fq=${outfolder}/${run}.fastq.gz
  echo ">>>step3：aspera开始下载数据" 
  while true
  do
    num=$((num+1))
    if [ ${num} -gt 5 ] ; then echo ">>>${run}下载失败, 已多次尝试" ; status=0 ; break ; fi

    if [ ! -f ${fq} ] || [ `md5sum ${fq} | awk '{print $1}'` != "${fastq_md5}" ] ; then
      echo ">>>第${num}次下载" 
      ascp -vQT -l 500M -P33001 -k 1 -i ${keyfile} era-fasp@${fastq_aspera} ${fq}
    else
      echo ">>>ascp成功下载${experiment_accession}数据, 第${num}次成功"
      break
    fi
  done
fi


if [ "${status}" == 0 ] ; then
  echo ">>>step2：prefetch开始下载数据" 
  prefetch ${experiment_accession} -O ${outfolder} && fastq-dump `ls ${outfolder}/*/*sra` -O ${outfolder} && echo ">>>prefetch成功下载${experiment_accession}数据"
fi
date
```

```shell
# step0_data/raw/02.submit_download.sh 
wd=/share/home/yzwl_zhouy/penglingwei/OR/raw/TGS/penglingwei
> part1.experiment_accession.txt
grep -v "^#" part1.species_number.tsv | while IFS=$'\t' read  species x x
do
  for experiment_accession in `awk -F "\t" -v species="${species}" '$3==species' output/sra_result.selected_species.tsv | cut -f 1`
  do
  echo ${experiment_accession} >> part1.experiment_accession.txt
  done
done

#for experiment_accession in `cat part1.experiment_accession.txt`
#do
#  echo ${experiment_accession}
#  sh 02.download_fastq.sh ${experiment_accession}
#  break
#done

csub -J plw_download -n 8 -R span[hosts=1] -o %J.out -e %J.err -q fat2 "cat part1.experiment_accession.txt | parallel -j 16 'sh 02.download_fastq.sh {} > log/{}.txt'"
```

ref
├── 01.species_url.sh
├── 02.crawler_ftp.py
├── 03.download.sh
├── input
├── output
└── ref

```shell
# 01.species_url.sh
echo -e "species\turl" > output/step1.species2url.tsv
grep -v "^#" input/species.tsv | while IFS=$'\t' read species x x
do
  awk -F "\t" -v species="${species}" '$8==species' input/assembly_summary_refseq.tsv | cut -f 8,20 >> output/step1.species2url.tsv 
done
echo "某些物种可能给出多个assembly，需人工甄别"
```

```python
# 02.crawler_ftp.py
import requests
from bs4 import BeautifulSoup
import pandas as pd
import os

os.system("echo -e 'species\tgenome\tgtf' > output/step2.species2ftp.tsv")
df = pd.read_table("output/step1.species2url.tsv", header=0, sep="\t", comment="#")
for row in df.index:
    species = df.loc[row, "species"]
    species = species.replace(" ", "_")
    url = df.loc[row, "url"]
    response = requests.get(url)
    html = response.text
    document = BeautifulSoup(html, "html.parser")
    for a in document.select("a"):
        text = a.text
        if "_genomic.fna.gz" in text and "_rna_from_genomic.fna.gz" not in text:
            genome = url + "/" + text 
        if "_genomic.gtf.gz" in text:
            gtf = url + "/" + text
    with open("output/step2.species2ftp.tsv", "a") as f:
        f.write(f"{species}\t{genome}\t{gtf}\n")
```

```shell
# 03.download.sh
awk 'NR>1' output/step2.species2ftp.tsv | while IFS=$'\t' read species genome gtf
do
  mkdir -p ref/${species}
  wget -c -P ref/${species} ${gtf}
  wget -c -P ref/${species} ${genome}
done
```

##### step2：比对参考基因组

```shell
# step2_mapping/01.mapping.sh 
execute_mapping() {
    fq=$1 ; genome=$2 ; bam=$3 ; technology=$4 ; thread=$5
    echo "${bam} `date`" >> start_record.txt
    #software
    minimap2=/share/home/yzwl_zhouy/software/minimap2-2.26_x64-linux/minimap2
    samtools=/share/home/yzwl_zhouy/software/miniconda3/bin/samtools
    if [ "${technology}" == "ONT" ] ; then
        parameter="-ax splice"
    elif [ "${technology}" == "Pacbio" ] ; then
        parameter="-ax splice:hq"
    else
        parameter="Erorr"
    fi
    ${minimap2} -t ${thread} ${parameter} --secondary=no ${genome} ${fq} | ${samtools} view -@ ${thread} -bS | ${samtools} sort -@ ${thread} -o ${bam}
    ${samtools} index -@ ${thread} ${bam}
    echo "${bam} `date`" >> end_record.txt
}
export -f execute_mapping

ref_folder=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS/step0_data/ref/ref
grep -v "^#" sample2filter_fq.tsv | while OFS=$'\t' read -r experiment_accession run fq species technology
do
  genome=`ls ${ref_folder}/${species}/*fna`
  bam=mapping/${experiment_accession}_${run}.sorted.bam
  csub -J plw_download -n 16 -R span[hosts=1] -o log/%J.out -e log/%J.err -q fat2 " \
  time execute_mapping $fq ${genome} ${bam} ${technology} 32
  "
done
```

##### step3：基因定量

```
export ref_folder=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS/step0_data/ref/ref
export isoquant="/share/home/yzwl_zhouy/software/miniconda3/envs/isoquant/bin/python3.10 /share/home/yzwl_zhouy/software/miniconda3/envs/isoquant/bin/isoquant.py"

execute_quant() {
    bam=$1 ; genome=$2 ; gtf=$3 ; out=$4 ; technology=$5 ; thread=$6
    type=`[ "${technology}" != "Pacbio" ] && echo nanopore || echo pacbio_ccs`
    strategy=`[ "${technology}" != "Pacbio" ] && echo sensitive_ont || echo sensitive_pacbio`

    ${isoquant} -d ${type} --reference ${genome} --model_construction_strategy ${strategy} --genedb ${gtf} -t ${thread} --bam ${bam} --labels output --prefix output --output ${out}
}
export -f execute_quant

grep -v "^#" sample2bam.tsv | while OFS=$'\t' read -r experiment_accession run bam species technology
do
  genome=`ls ${ref_folder}/${species}/*fna`
  out=quant/${experiment_accession}_${run} ; mkdir -p ${out}
  gtf=`ls ${ref_folder}/${species}/*gtf`
  fixed_gtf=quant/gtf/${species}.`basename ${gtf} | sed "s/.gtf$/.fixed.gtf/"`
  if [ ! -f ${fixed_gtf} ] ; then
    cat ${gtf} | grep -P '\btranscript_id\s+"[^"]+"' | grep -v '; transcript_id "unknown_transcript_' > ${fixed_gtf}
  fi
  csub -J plw_quant -n 8 -R span[hosts=1] -o log/%J.out -e log/%J.err -q fat2 " \
  time execute_quant ${bam} ${genome} ${fixed_gtf} ${out} ${technology} 16
  "
done
```

##### step4：关联CORD与NCBI中OR基因并构建OR基因表达矩阵

CORD并未告知OR基因对应的NCBI基因ID，因此试图通过染色体坐标为媒介重新建立联系，但是minimap2并不能完全回比

```shell
step4_ORexpression/01.ensembl_OR.sh 

species_txt=`grep -v "^#" input/species_number.tsv | awk -F "\t" '{gsub(" ", "_", $1) ; print $1}'`

# step1：拷贝指定物种OR序列，并以species命名
mkdir -p step1_OR_sequence
for species in `grep -v "^#" input/species_number.tsv | awk -F "\t" '{gsub(" ", "_", $1) ; print $1}'`
do
  break ; echo "无需重复运行step1"
  awk -F "\t" -v s=${species} '{gsub(" ", "_", $4) ; if($4==s){print $4"\t"$6}}' /share/home/yzwl_zhouy/data/CORD_new/species_list.txt | while read -r species name 
  do
  cp /share/home/yzwl_zhouy/data/CORD_new/dna_sequence/${name}.func.fasta step1_OR_sequence/${species}.func.fasta
  done
done

# step2：CORD中OR序列回比参考基因组
mkdir -p step2_mapping
ref_folder=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS/step0_data/ref/ref
minimap2=/share/home/yzwl_zhouy/software/minimap2-2.26_x64-linux/minimap2
for species in `grep -v "^#" input/species_number.tsv | awk -F "\t" '{gsub(" ", "_", $1) ; print $1}'`
do
  break ; echo "无需重复运行step2"
  genome=`ls ${ref_folder}/${species}/*fna`
  long_read=step1_OR_sequence/${species}.func.fasta
  csub -J step2_plw -n 8 -R span[hosts=1] -o log/${species}.out -e log/${species}.err -q fat2 " \
  echo ${minimap2} -t 16 -a --secondary=no ${genome} ${long_read} 
  ${minimap2} -t 16 -a --secondary=no ${genome} ${long_read} > step2_mapping/${species}.sam
  "
done

# step3：回比的sam文件转换为gtf格式
mkdir -p step3_sam2gtf
for species in `grep -v "^#" input/species_number.tsv | awk -F "\t" '{gsub(" ", "_", $1) ; print $1}'`
do
  break ; echo "无需重复运行step3"
  grep -v "^@" step2_mapping/${species}.sam | \
  awk '$2=="16"||$2=="0"' | awk '$6 ~ /^([0-9]+)M$/' | \
  awk -v OFS="\t" '{
    sub("M", "", $6) ; 
    if ($2=="0") {
      print $3, "CORD", "exon", $4, $4+$6-1, ".", "+", ".", "gene_id \"" $1 "_gene\"; transcript_id \"" $1 "_transcript\"" 
    } else{
      print $3, "CORD", "exon", $4, $4+$6-1, ".", "-", ".", "gene_id \"" $1 "_gene\"; transcript_id \"" $1 "_transcript\"" 
    }
    fi
  }' > step3_sam2gtf/${species}.gtf 
done

# step4：明确CORD中OR基因与NCBI基因的关系
ref_folder=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS/step3_quant/quant/gtf
gffcompare=/share/home/yzwl_zhouy/software/miniconda3/bin/gffcompare
mkdir -p step4_gffcompare
for species in `grep -v "^#" input/species_number.tsv | awk -F "\t" '{gsub(" ", "_", $1) ; print $1}'`
do
  if [ ! "${species}" = "Bos_taurus" ] ; then continue ; fi
  gtf=`ls ${ref_folder}/${species}.*.fixed.gtf`
  mkdir -p step4_gffcompare/${species} 
  ${gffcompare} -r ${gtf} step3_sam2gtf/${species}.gtf -T -o step4_gffcompare/${species}/gffcmp 
  cat step4_gffcompare/${species}/gffcmp.tracking | \
  awk '$4=="="{
    split($5, s, "|") ; $5=s[2] ; sub("_transcript", "", $5) ; 
    split($3, s, "|") ; $3=s[1] ;
    print $5"\t"$3
  }' > step4_gffcompare/${species}/output.tsv
done 

# step5
mkdir -p step5_expression_matrix
for species in ${species_txt}
do
  break ; echo "无需重复运行step5"
  grep -v "^#" sample.tsv | awk -v s=${species} '$3==s' | while IFS=$'\t' read -r experiment_accession run species
  do
    tsv=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/Chordata_TGS/step3_quant/quant/${experiment_accession}_${run}/output/output.gene_tpm.tsv
    if [ -f ${tsv} ] ; then
      mkdir -p step5_expression_matrix/${species}
      grep -v "^#" ${tsv} > step5_expression_matrix/${species}/${experiment_accession}_${run}.tsv
    fi
  done
  python3 01.cbind_expresiong.py ${species} 
  echo ${species}
done
```

```python
02.cbind_expresiong.py 
import os
import pandas as pd
import sys
species = sys.argv[1]

def bind(species):
    folder = f"step5_expression_matrix/{species}"
    print(f"step4_gffcompare/{species}/output.tsv")
    ORgenes = pd.read_table(f"step4_gffcompare/{species}/output.tsv", header=None, sep="\t").loc[:, 1].tolist() #NCBI基因名的形式 
    dfs = pd.DataFrame(ORgenes, columns=["gene"])
    for tsv in os.listdir(folder):
       sample = tsv.replace(".tsv", "")
       df = pd.read_table(f"{folder}/{tsv}", header=None, sep="\t", names=["gene", sample])
       dfs = pd.merge(dfs, df, how="left", on="gene")
    dfs.fillna(0).to_csv(f"step5_expression_matrix/{species}.tsv", header=True, index=False, sep="\t")

    #>>>tmp
    dfs = dfs.fillna(0).set_index("gene", drop=True)
    print(dfs)
    dfs[dfs.sum(axis=1) != 0].to_csv(f"step5_expression_matrix/tmp_{species}.tsv", header=True, index=True, sep="\t")  
    #<<<tmp
bind(species)
```







### 20240306：爬虫NCBI的bioSample和bioProject的详细信息

张文刚老师需要确定二代转录组数据中阉牛的样本，因此爬虫cattleGTEx中8000+样本，并输出样本项目号和样本号的详细信息为一个文件。

```
import requests
from bs4 import BeautifulSoup
import pandas as pd

def sra2biosample(sra):
    url = f"https://www.ncbi.nlm.nih.gov/sra/{sra}[accn]"
    response = requests.get(url)
    html = response.text
    document = BeautifulSoup(html, "xml")
    biosample = document.select_one("a[title='Link to BioSample']").text
    return biosample


def getBiosampleInformation(biosample):
    url = f"https://www.ncbi.nlm.nih.gov/biosample/{biosample}"
    response = requests.get(url)
    html = response.text
    document = BeautifulSoup(html, "xml")
    div = document.select_one(".docsum")
    dls = div.select("dl")

    results = []
    for dl in dls:
        dt = dl.select_one("dt") 
        dd = dl.select_one("dd")
        term = dt.text.strip()
        if term == "Organism":
            description = []
            for children in dd.children:
                text = children.text.strip()
                if len(text) == 0: # 避免空行
                    continue
                description += [text]
            description = " | ".join(description)
            results.append(f"{term} => {description}")
        elif term == "Attributes":
            description = ""
            trs = dd.select("tr")
            for tr in trs:
                th = tr.select_one("th")
                td = tr.select_one("td")
                description += f"{th.text}: {td.text.strip()}; "
            results.append(f"{term} => {description}")
        else:
            description = dd.text.strip()
            results.append(f"{term} => {description}")
    return "\n".join(results)


class GetBioprojectInformation():
    def __init__(self, bioproject):
        url = f"https://www.ncbi.nlm.nih.gov/bioproject/{bioproject}"
        response = requests.get(url)
        html = response.text
        document = BeautifulSoup(html, "xml")
        self.bioproject = bioproject
        self.url = url
        self.document = document
    # description
    def Description(self):
        description = self.document.select_one("#DescrAll")
        description = self.document.select_one(".Description") if description is None else description
        description = description.text.replace(" Less...", ".")
        return description
    # table
    def Table(self):
        results = []
        table = self.document.select_one("#CombinedTable")
        for tr in table.select("tr"):
            term_description = []
            for td in tr.select("td"):
                term_description += [td.text.strip()]
            term, description = term_description[0], " | ".join(term_description[1: ])
            results += [f"{term} => {description}"]
        return "\n".join(results)
import os
def main():
    out_folder = "result"
    record = "record.txt"
    biosample2information = {}
    df = pd.read_table("Metadata_FarmGTEx_cattle_V0.tsv", header=0, sep="\t", nrows=10)

    for row in df.index:
        sra, bioproject = df.loc[row, ["Sample", "Bioproject"]].tolist()
        out_file = f"{out_folder}/{bioproject}.txt" 

        # bioSample
        try:
            biosample = sra2biosample(sra)
        except:
            with open(record, "a") as f:
                f.write(f"{sra}\n")
            continue

        # bioProject
        if not os.path.exists(out_file):
            try:
                getBioprojectInformation = GetBioprojectInformation(bioproject)
                bioproject_information = getBioprojectInformation.Description() + "\n" + getBioprojectInformation.Table()
            except:
                bioproject_information = "#Error#"
            with open(out_file, "w") as f:
                f.write(f">>>{bioproject}\n{bioproject_information}\n\n")

        # bioSample
        try:
            if biosample not in biosample2information:
                biosample = sra2biosample(sra)
                biosample_information = getBiosampleInformation(biosample)
                biosample2information[biosample] = biosample_information
            else:
                biosample_information = biosample2information[biosample]

        except:
            biosample_information = "#Error#"
            with open(record, "a") as f:
                f.write(f"{sra}\n")
        with open(out_file, "a") as f:
            f.write(f">>>{biosample} {sra}\n" + biosample_information + "\n")



if __name__ == "__main__":
    main()



```

###  20240311：油红O染色数据分析

##### step1：ImageJ软件下载

```
https://imagej.net/downloads
```

##### step2：软件使用

参考资料

```
流程步骤：https://zhuanlan.zhihu.com/p/583864328
批量自动化运行：https://www.bilibili.com/video/BV1AV4y1t7g6/?vd_source=bc88330cea2e95bd9385b653b5c6af5f
```

操作步骤

![image-20240311202013429](0记录本/image-20240311202013429.png)

流程记录(用于批量运行)

```
title=getTitle();
run("RGB Stack");
setAutoThreshold("Triangle");
run("Set Measurements...", "area mean integrated limit area_fraction IntDen display redirect=None decimal=3");
run("Convert to Mask", "method=Triangle background=Light calculate list");
run("Measure");
```



### 2040317：cattleGTEx和pigGTEx数据库中OR基因组织表达

#####  根据CORD数据库注释Ensembl中OR基因

CORD数据库并没有给出OR基因的坐标，因此尝试通过序列回比的方式找回坐标，生成gtf，再与Ensembl gtf进行比较，确定OR基因ID，但是step2的mapping步骤并不能完全将来源于基因组的OR序列重新回比而找回坐标

.
├── 01.get_ensembl_OR_gene.sh
├── step1_OR_sequence
│   ├── Bos_taurus.func.fasta
│   └── Sus_scrofa.func.fasta
├── step2_mapping
│   ├── Bos_taurus.sam
│   └── Sus_scrofa.sam
├── step3_sam2gtf
│   ├── Bos_taurus.gtf
│   └── Sus_scrofa.gtf
└── step4_gffcompare
    ├── Bos_taurus
    │   ├── gffcmp.annotated.gtf
    │   ├── gffcmp.loci
    │   ├── gffcmp.stats
    │   ├── gffcmp.tracking
    │   └── output.tsv
    └── Sus_scrofa
        ├── gffcmp.annotated.gtf
        ├── gffcmp.loci
        ├── gffcmp.stats
        ├── gffcmp.tracking
        └── output.tsv

```shell
# 01.get_ensembl_OR_gene.sh
ref_folder=/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx_tissue/ref

# step1：拷贝指定物种OR序列，并以species命名
mkdir -p step1_OR_sequence
for species in ${species_txt} 
do
  break ; echo "手动操作"
  awk -F "\t" -v s=${species} '{gsub(" ", "_", $4) ; if($4==s){print $4"\t"$6}}' /share/home/yzwl_zhouy/data/CORD_new/species_list.txt | while read -r species name 
  do
  cp /share/home/yzwl_zhouy/data/CORD_new/dna_sequence/${name}.func.fasta step1_OR_sequence/${species}.func.fasta
  done
done

# step2：CORD中OR序列回比参考基因组
mkdir -p step2_mapping
minimap2=/share/home/yzwl_zhouy/software/minimap2-2.26_x64-linux/minimap2
for species in Sus_scrofa 
do
  genome=`ls ${ref_folder}/${species}/*fa`
  long_read=step1_OR_sequence/${species}.func.fasta
  ${minimap2} -t 16 -a --secondary=no ${genome} ${long_read} > step2_mapping/${species}.sam
done

# step3：回比的sam文件转换为gtf格式
mkdir -p step3_sam2gtf
for species in Sus_scrofa 
do
  grep -v "^@" step2_mapping/${species}.sam | \
  awk '$2=="16"||$2=="0"' | awk '$6 ~ /^([0-9]+)M$/' | \
  awk -v OFS="\t" '{
    sub("M", "", $6) ; 
    if ($2=="0") {
      print $3, "CORD", "exon", $4, $4+$6-1, ".", "+", ".", "gene_id \"" $1 "_gene\"; transcript_id \"" $1 "_transcript\"" 
    } else{
      print $3, "CORD", "exon", $4, $4+$6-1, ".", "-", ".", "gene_id \"" $1 "_gene\"; transcript_id \"" $1 "_transcript\"" 
    }
    fi
  }' > step3_sam2gtf/${species}.gtf 
done

# step4：明确CORD中OR基因与NCBI基因的关系
gffcompare=/share/home/yzwl_zhouy/software/miniconda3/bin/gffcompare
mkdir -p step4_gffcompare
for species in Sus_scrofa 
do
  gtf=`ls ${ref_folder}/${species}/*.gtf`
  mkdir -p step4_gffcompare/${species} 
  ${gffcompare} -r ${gtf} step3_sam2gtf/${species}.gtf -T -o step4_gffcompare/${species}/gffcmp 
  cat step4_gffcompare/${species}/gffcmp.tracking | \
  awk '$4=="="{
    split($5, s, "|") ; $5=s[2] ; sub("_transcript", "", $5) ; 
    split($3, s, "|") ; $3=s[1] ;
    print $5"\t"$3
  }' > step4_gffcompare/${species}/output.tsv
done 
```



##### 格式化cattleGTEx和pigGTEx提供的表达数据

/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx_tissue

.
├── 01.format.py
├── 02.heatmap.R
├── step0_OR_gene
│   ├── Bos_taurus.OR_gene.txt
│   └── Sus_scrofa.OR_gene.txt
├── step1_GTEx_data
│   ├── Bos_taurus
│   ├── raw
│   └── Sus_scrofa
├── step2_tissue_expression
│   ├── Bos_taurus.OR_expression.tsv
│   └── Sus_scrofa.OR_expression.tsv
└── step3_heatmap
    ├── Bos_taurus.OR_expression.tiff
    └── Sus_scrofa.OR_expression.tiff

```python
#01.format.py
import pandas as pd
import os

# Sus_scrofa
OR_genes = pd.read_table("step0_OR_gene/Sus_scrofa.OR_gene.txt", header=None).loc[:, 0]
dfs = pd.DataFrame()
folder = "step1_GTEx_data/Sus_scrofa/"
for tsv in os.listdir(folder):
    tissue = tsv.split(".")[0]
    df = pd.read_table(f"{folder}/{tsv}", header=0, sep="\t", index_col=0)
    df = df.loc[OR_genes, :]
    df = pd.DataFrame(df.mean(axis=1))
    df.columns = [tissue]
    dfs = pd.concat([dfs, df], axis=1)
dfs.fillna(0).to_csv("step2_tissue_expression/Sus_scrofa.OR_expression.tsv", header=True, index=True, sep="\t")

# Bos_taurus
dfs = pd.DataFrame()
folder = "step1_GTEx_data/Bos_taurus"
for tsv in os.listdir(folder):
    gene = tsv.split(".")[0]
    df = pd.read_table(f"{folder}/{tsv}", header=0, sep="\t", index_col=0).loc[:, ["mean(TPM)"]]
    df.columns = [gene]
    df = df.transpose()
    dfs = pd.concat([dfs, df], axis=0)
dfs.fillna(0).to_csv("step2_tissue_expression/Bos_taurus.OR_expression.tsv", header=True, index=True, sep="\t")
```

```R
# 02.heatmap.R
library(pheatmap)
plot_heatmap <- function(df) {
    p <- pheatmap(df,
                # cellwidth=100, cellheight=18,
                fontsize=15, 
                # labels_col=groups,
                angle_col="45", 
                # cluster_cols = FALSE,
                show_rownames = FALSE,
                border_color = "black",
                # display_number=T,
                color=colorRampPalette(c("#4576B4", "white", "#DA3428"))(50),
                # color=colorRampPalette(c("white", "#DA3428"))(50),
                main = ""
                )
    return(p)
}

df <- read.table("step2_tissue_expression/Sus_scrofa.OR_expression.tsv", header=T, row.names=1, sep="\t")
df <- log10(df+0.001)
tiff("step3_heatmap/Sus_scrofa.OR_expression.tiff", width=24, height=24, units="cm", res=600, compression="lzw")
plot_heatmap(df)
dev.off()

df <- read.table("step2_tissue_expression/Bos_taurus.OR_expression.tsv", header=T, row.names=1, sep="\t")
df <- log10(df+0.001)
tiff("step3_heatmap/Bos_taurus.OR_expression.tiff", width=24, height=12, units="cm", res=600, compression="lzw")
plot_heatmap(df)
dev.off()
```

cattle结果

![](0记录本/Bos_taurus.cattleGTEx.OR_expression.png)

pig结果

![](0记录本/Sus_scrofa.pigGTEx.OR_expression.png)

### 20240319：下载精子转录组数据

##### step1：获取tissue含sperm的biosample

```
https://www.ncbi.nlm.nih.gov/biosample中键入“sperm”
”Attribute name“栏选定“tissue”
Send to > File >  Summary(text) > Create File
biosample_result.txt
```

##### step2：提取SRA

```
grep "SRA: " biosample_result.txt | awk '{split($0, arr, ";") ; for(i=1; i<=length(arr); i++) {if(arr[i] ~ " SRA: ") print arr[i]}}' | cut -d " " -f 3 > sra.txt
https://www.ncbi.nlm.nih.gov/sites/batchentrez中选中sra、选择sra.txt检索
点击batchentrez结果网页末尾的链接
点击Advanced得到#34搜索码
键入#34 AND ("transcriptomic"[Source] OR "rna seq"[Strategy]) 进行搜索
```

##### step3：手动筛选

##### step4：下载sra数据和进行二代RNA-seq分析

.
├── 00.submit.sh
├── 01.download_fastq.sh
├── 02.ngs.sh
├── input
│   ├── Ovis_aries
│   └── Sus_scrofa
├── log
├── output
│   ├── Ovis_aries
│   └── Sus_scrofa
├── raw
│   ├── Ovis_aries
│   └── Sus_scrofa
├── ref
│   ├── Ovis_aries
│   └── Sus_scrofa
└── result
    ├── 02.heatmap.R
    ├── Ovis_aries.ORgene_expression.sperm.tiff
    └── Sus_scrofa.ORgene_expression.sperm.tiff

```shell
# 00.submit.sh
species="Sus_scrofa"
species="Ovis_aries"

for experiment_accession in `grep -v "^#" input/${species}/experiment_accession.txt`
do
  break
  csub -J plw -q cpu_www -o ${experiment_accession}.out -e ${experiment_accession}.err -n 1 -R span[hosts=1] " \
  sh 01.download_fastq.sh ${experiment_accession} raw/${species}
  "
done

export genome=`ls ref/${species}/*_genomic.fna`
export gtf=`ls ref/${species}/*_genomic.gtf`
# step1：预处理 (只执行一次)
#csub -J plw -q cpu -o log/${sample}.out -e log/${sample}.err -n 48 -R span[hosts=1] "sh 02.ngs.sh preprocess -g ${genome} -f ${gtf} -t 48"
#exit

# step2：
grep -v "^#" input/${species}/raw_data.tsv | while IFS=$'\t' read -r sample fq1 fq2 
do
    break
    csub -J plw -q cpu -o log/${sample}.out -e log/${sample}.err -n 12 -R span[hosts=1] " \
    sh 02.ngs.sh execute -s ${sample} -1 ${fq1} -2 ${fq2} -g ${genome} -f ${gtf} -o output/${species} -t 12 
    "
done

sh 02.ngs.sh matrix -e input/${species}/ORgenes.txt -o output/${species}
```

```shell
# 01.download_fastq.sh
# input
experiment_accession=$1 ; wd=$2
keyfile=/share/home/yzwl_zhouy/software/aspera-3.7.4/etc/asperaweb_id_dsa.openssh

# output
outfolder=${wd}/${experiment_accession} ; mkdir -p ${outfolder}
tsv=${outfolder}/${experiment_accession}.tsv
url="https://www.ebi.ac.uk/ena/portal/api/filereport?accession=${experiment_accession}&result=read_run&fields=run_accession,fastq_md5,fastq_aspera&format=tsv&download=true&limit=0"

echo "=>=>=>${experiment_accession}"
date

echo ">>>step1：从ebi中下载${experiment_accession}的详细信息" 
wget -c ${url} -O ${tsv} 
if [ -s "${tsv}" ] ; then 
  status=1 
else
  echo ">>>无法获得ebi中${experiment_accession}的样本信息" 
  status=0
fi

single () {
  fq=${outfolder}/${run}.fastq.gz
  num=0
  while [ "${status}" == 1 ]
  do
    num=$((num+1))
    if [ ${num} -gt 5 ] ; then echo ">>>${run}下载失败, 已多次尝试" ; status=0 ; break ; fi
    if [ ! -f ${fq} ] || [ `md5sum ${fq} | awk '{print $1}'` != "${fastq_md5}" ] ; then
      echo ">>>第${num}次下载" 
      ascp -vQT -l 500M -P33001 -k 1 -i ${keyfile} era-fasp@${fastq_aspera} ${fq}
    else
      echo ">>>ascp成功下载${experiment_accession}数据, 第${num}次成功"
      break
    fi
  done

}

pair () {
  fastq_md51=`echo ${fastq_md5} | awk -F ";" '{print $1}'`
  fastq_md52=`echo ${fastq_md5} | awk -F ";" '{print $2}'`
  fastq_aspera1=`echo ${fastq_aspera} | awk -F ";" '{print $1}'`
  fastq_aspera2=`echo ${fastq_aspera} | awk -F ";" '{print $2}'`
  fq1=${outfolder}/${run}_1.fastq.gz
  fq2=${outfolder}/${run}_2.fastq.gz
  num=0
  while [ "${status}" == 1 ]
  do
    num=$((num+1))
    if [ ${num} -gt 5 ] ; then echo ">>>${run}下载失败, 已多次尝试" ; status=0 ; break ; fi
    if [ ! -f ${fq1} ] || [ ! -f ${fq2} ] || [ `md5sum ${fq1} | awk '{print $1}'` != "${fastq_md51}" ] || [ `md5sum ${fq2} | awk '{print $1}'` != "${fastq_md52}" ] ; then
      echo ">>>第${num}次下载" 
      ascp -vQT -l 500M -P33001 -k 1 -i ${keyfile} era-fasp@${fastq_aspera1} ${fq1}
      ascp -vQT -l 500M -P33001 -k 1 -i ${keyfile} era-fasp@${fastq_aspera2} ${fq2}
    else
      echo ">>>ascp成功下载${experiment_accession}数据, 第${num}次成功"
      break
    fi
  done
}

awk 'NR>1' ${tsv} | while IFS=$'\t' read -r run fastq_md5 fastq_aspera
do
  echo ">>>step2：检测fastq_aspera是否有效" 
  if [ "${fastq_aspera}" == "" ] ; then echo ">>>fastq_aspera无效" ; status=0 ; fi
  end=`echo ${fastq_aspera} | awk -F ";" '{print NF}'`
  if [ "${end}" == 1 ] ; then
    single
  else
    pair
  fi
done

if [ "${status}" == 0 ] ; then
  echo ">>>step2：prefetch开始下载数据" 
  prefetch ${experiment_accession} -O ${outfolder} && fastq-dump --split-3 `ls ${outfolder}/*/*sra` -O ${outfolder} && echo ">>>prefetch成功下载${experiment_accession}数据"
fi
date
```

```shell
# 02.ngs.sh
# module
preprocess () {
    hisat2-build -p ${thread} ${genome} ${genome}
    grep -P '\btranscript_id\s+"[^"]+"' ${gtf} | grep -v '; transcript_id "unknown_transcript_' > ${gtf}.fixed
}

quality_control () {
    output=${out_folder}/quality_control ; mkdir -p ${output}
    qc_fq1=${output}/${sample}_R1.fq
    qc_fq2=${output}/${sample}_R2.fq
    #fastp -i ${raw_fq1} -o ${qc_fq1} -I ${raw_fq2} -O ${qc_fq2} -j ${output}/${sample}.json -h ${output}/${sample}.josn
}

genome_mapping () {
    output=${out_folder}/genome_mapping ; mkdir -p ${output}
    bam=${output}/${sample}.sorted.bam
    hisat2 -p ${thread} --dta -t -x ${genome} -1 ${qc_fq1} -2 ${qc_fq2} | samtools view -@ ${thread} -bS | samtools sort -@ ${thread} -o ${bam}
}

gene_quant () {
    output=${out_folder}/gene_quant/${sample} ; mkdir -p ${output}
    stringtie ${bam} -G ${gtf}.fixed -p ${thread} -A ${output}/gene_expression.tsv -B -C ${output}/transcript_coverage.tsv -e -o ${output}/transcript.gtf
}


matrix () {
python3 - << END
import os
import pandas as pd
import os

genes, out_folder = os.environ["genes"], os.environ["out_folder"]
folder = f"{out_folder}/gene_quant"
genes = pd.read_table(genes, header=None).loc[:, 0].tolist() 
dfs = pd.DataFrame({"gene": []})
for sample in os.listdir(folder):
   df = pd.read_table(f"{folder}/{sample}/gene_expression.tsv", header=0, sep="\t").loc[:, ["Gene ID", "TPM"]]
   df.columns = ["gene", sample]
   df = df[df["gene"].isin(genes)]
   dfs = pd.merge(dfs, df, how="outer", on="gene")
dfs.fillna(0).to_csv(f"{out_folder}/gene_expression.TPM.tsv", header=True, index=False, sep="\t")

END
}


subcommand=$1
shift 1

# parameter
while getopts "s:1:2:g:f:e:t:o:" opt
do
case $opt in
    s) sample=$OPTARG;;
    1) raw_fq1=$OPTARG;;
    2) raw_fq2=$OPTARG;;
    g) genome=$OPTARG;;
    f) gtf=$OPTARG;;
    e) genes=$OPTARG;;
    t) thread=$OPTARG;;
    o) out_folder=$OPTARG;;
    \?) echo "Invalid option: -$OPTARG" >&2; exit 1;;
esac
done

# subcommand
case ${subcommand} in 
    preprocess)
        preprocess
        ;;
    execute)
        quality_control
        genome_mapping
        gene_quant
        ;;
    matrix)
        export genes=${genes}
        export out_folder=${out_folder}
        matrix
        ;;
esac
```



### 20240326：确定组织特异表达基因分析软件

##### step1：查阅网上现有软件

```
2019
TissueEnrich: Tissue-specific gene enrichment analysis
2020
tspex: a tissue-specificity calculator for gene expression data
2022
Robust and Rigorous Identification of Tissue-Specific Genes by Statistically Extending Tau Score
2020
SPECS: a non-parametric method to identify tissue-specific molecular features for unbalanced sample groups
```

##### step2：tspex

tspex教程详细，整合多种方法组织特异表达的指标

```
usage: tspex [-h] [-l] [-d] [-t THRESHOLD] input_file output_file method

Compute gene tissue-specificity from an expression matrix and save the output.

positional arguments:
  input_file            Expression matrix file in the TSV, CSV or Excel
                        formats.
  output_file           Output TSV file containing tissue-specificity values.
  method                Tissue-specificity metric. Allowed values are:
                        "counts", "tau", "gini", "simpson",
                        "shannon_specificity", "roku_specificity", "tsi",
                        "zscore", "spm", "spm_dpm", "js_specificity",
                        "js_specificity_dpm".

optional arguments:
  -h, --help            show this help message and exit
  --version             show program's version number and exit
  -l, --log             Log-transform expression values. (default: False)
  -d, --disable_transformation
                        By default, tissue-specificity values are transformed
                        so that they range from 0 (perfectly ubiquitous) to 1
                        (perfectly tissue-specific). If this parameter is
                        used, transformation will be disabled and each metric
                        will have have a diferent range of possible values.
                        (default: False)
  -t THRESHOLD, --threshold THRESHOLD
                        Threshold to be used with the "counts" metric. If
                        another method is chosen, this parameter will be
                        ignored. (default: 0)
```

依据下面文章评估的结果，method选用“tau”较好

```
A benchmark of gene expression tissue-specificity metrics
```

##### step3

不适用OR基因这种低表达



### 20240331：cattleGTEx和pigGTEx数据库中OR基因样本表达

/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx_sample

.
├── 01_1.NCBI_OR.py
├── 01_2.NCBI_OR.sh
├── 02.Ensembl_OR.py
├── 03.animalGTEx.sh
├── 04_1.preprocess.py
├── 04_2.group_heatmap.R
├── 05_1.mean_std.py
├── 05_2.bubble_chart.R
├── input
│   ├── Bos_taurus.CORD_OR.func.fasta
│   └── Sus_scrofa.CORD_OR.func.fasta
├── OR_gene
│   ├── Bos_taurus.Ensembl_ORgene.tsv
│   ├── Bos_taurus.Ensembl_ORgene.txt
│   ├── Bos_taurus.NCBI_ORgene.tsv
│   ├── Sus_scrofa.Ensembl_ORgene.tsv
│   ├── Sus_scrofa.Ensembl_ORgene.txt
│   └── Sus_scrofa.NCBI.ORgene.tsv
├── output
│   ├── step1_NCBI_OR
│   ├── step2_Ensembl_OR
│   ├── step3_animalGTEx
│   ├── step4_global_heatmap
│   └── step5_tissue_specific
└── ref
    ├── download_url.txt
    ├── Ensembl
    ├── NCBI
    └── README.md

对animalGTEX中牛和猪的OR基因表达数据进行分析，对样本的聚类情况进行呈现，还按表达梯度展示了组织的表达情况

##### step1：获取NCBI gtf中的OR基因和CDS序列

```
#01_1.NCBI_OR.py
import pandas as pd
import os
def parseGtf(gtf):
    df = pd.read_table(gtf, header=None, sep="\t", comment="#", low_memory=False)
    df.columns = ["chromosome", "source", "type", "start", "end", "score", "strand", "phase", "attribute"]
    df = df[df["type"]=="CDS"]
    function1 = lambda attribute: [x.split("\"")[1] for x in attribute.split(";") if "gene_id" in x][0]
    function2 = lambda attribute: [x.split("\"")[1] for x in attribute.split(";") if "transcript_id" in x][0]
    function3 = lambda attribute: [x.split("\"")[1] for x in attribute.split(";") if "protein_id" in x][0]
    #function3 = lambda attribute: [x.split("\"")[1] for x in attribute.split(";") if "gene_name" in x][0] if "gene_name" in attribute else "-"
    df = df[df["attribute"].str.contains("olfactory receptor")]
    df["gene"] = df["attribute"].apply(function1)
    df["transcript"] = df["attribute"].apply(function2)
    df["protein"] = df["attribute"].apply(function3)
    df = df.drop_duplicates(subset=["transcript"])
    return df.loc[:, ["gene", "transcript", "protein"]]

# Bos taurus
NCBI_gtf = "ref/NCBI/Bos_taurus.GCF_002263795.3.gtf"
output = "output/step1_NCBI_OR" ; os.system(f"mkdir -p {output}")
#parseGtf(NCBI_gtf).to_csv(f"{output}/Bos_taurus.OR_gene.tsv", header=False, index=False, sep="\t")
# Sus scrofa
NCBI_gtf = "ref/NCBI/Sus_scrofa.GCF_000003025.6.gtf"
output = "output/step1_NCBI_OR" ; os.system(f"mkdir -p {output}")
parseGtf(NCBI_gtf).to_csv(f"{output}/Sus_scrofa.OR_gene.tsv", header=False, index=False, sep="\t")
```

```
#01_2.NCBI_OR.sh
# Bos taurus
NCBI_fasta=ref/NCBI/Bos_taurus.GCF_002263795.3.cds.fna
output=output/step1_NCBI_OR 
#> ${output}/Bos_taurus.OR_gene.fasta
for protein in `cut -f 3 ${output}/Bos_taurus.OR_gene.tsv`
do
    break #!!!!!!!!!!!!!!!!!!!!
    seqkit grep -n -r -p "_${protein}_" ${NCBI_fasta} >> ${output}/Bos_taurus.OR_gene.fasta
done

# Sus scrofa
NCBI_fasta=ref/NCBI/Sus_scrofa.GCF_000003025.6.cds.fna
output=output/step1_NCBI_OR 
> ${output}/Sus_scrofa.OR_gene.fasta
for protein in `cut -f 3 ${output}/Sus_scrofa.OR_gene.tsv`
do
    seqkit grep -n -r -p "_${protein}_" ${NCBI_fasta} >> ${output}/Sus_scrofa.OR_gene.fasta
done
```

##### step2：比较CDS序列以获得Ensembl的OR基因

```
#02.Ensembl_OR.py
import pyfastx
import os
import numpy as np

def getEnsemblOR(Ensembl_fasta, NCBI_fasta, output):
    Ename2seq = {name: seq for name, seq in pyfastx.Fastx(Ensembl_fasta, uppercase=True)}
    Nname2seq = {name: seq for name, seq in pyfastx.Fastx(NCBI_fasta, uppercase=True)}
    os.system("> test")
    f = open(output, "a")
    for Nname in Nname2seq:
        print(Nname)
        Nseq = Nname2seq[Nname]
        Enames = []
        for Ename in Ename2seq:
            Eseq = Ename2seq[Ename]
            if len(Nseq) != len(Eseq):
                continue
            if sum(np.array(list(Nseq)) != np.array(list(Eseq))) > 1: # 允许不同基因组SNP
                continue
            Enames.append(Ename)
        line = f'{Nname}\t{",".join(Enames)}'
        f.write(line + "\n")
    f.close()

os.system("mkdir -p output/step2_Ensembl_OR")
# Bos taurus
Ensembl_fasta = "ref/Ensembl/Bos_taurus.ARS-UCD1.2.cds.all.fa"
NCBI_fasta = "output/step1_NCBI_OR/Bos_taurus.OR_gene.fasta" # OR gene
output = "output/step2_Ensembl_OR/Bos_taurus.ensembl_OR.tsv" ; os.system(f"> {output}")
getEnsemblOR(Ensembl_fasta, NCBI_fasta, output)

# Sus scrofa
Ensembl_fasta = "ref/Ensembl/Sus_scrofa.Sscrofa11.1.cds.all.fa"
NCBI_fasta = "output/step1_NCBI_OR/Sus_scrofa.OR_gene.fasta" # OR gene
output = "output/step2_Ensembl_OR/Sus_scrofa.ensembl_OR.tsv" ; os.system(f"> {output}")
getEnsemblOR(Ensembl_fasta, NCBI_fasta, output)
```
##### step3：获取animalGTEx的表达数据

主要是手动整理而得

```
#03.animalGTEx.sh
Ensembl_tsv=output/step2_Ensembl_OR/Bos_taurus.ensembl_OR.tsv
ENsembl_gtf=ref/Ensembl/Bos_taurus.ARS-UCD1.2.96.gtf
mkdir -p output/step3_animalGTEx ; output=output/step3_animalGTEx/Bos_taurus.Ensembl_ORgene.txt
grep -f <(awk '$2!=""{print $2}' ${Ensembl_tsv} | cut -d "." -f 1) <(awk '$3=="transcript"' ${ENsembl_gtf}) | cut -d "\"" -f 2 | sort | uniq > ${output}

Ensembl_tsv=output/step2_Ensembl_OR/Sus_scrofa.ensembl_OR.tsv
ENsembl_gtf=ref/Ensembl/Sus_scrofa.Sscrofa11.1.100.gtf
mkdir -p output/step3_animalGTEx ; output=output/step3_animalGTEx/Sus_scrofa.Ensembl_ORgene.txt
grep -f <(awk '$2!=""{print $2}' ${Ensembl_tsv} | cut -d "." -f 1) <(awk '$3=="transcript"' ${ENsembl_gtf}) | cut -d "\"" -f 2 | sort | uniq > ${output}

# 数据借鉴version1，参考代码
# Bos taurus
#import pandas as pd
#import os
#dfs = pd.DataFrame()
#for tsv in os.listdir("raw"):
#    gene = tsv.split(".")[0]
#    tsv = f"raw/{tsv}"
#    df = pd.read_table(tsv, header=0, sep="\t")
#    df = df.loc[1:, ["Sample", "TPM"]].set_index("Sample").rename(columns={"TPM": gene}).transpose() # tsv第二行没有数据
#    dfs = pd.concat([dfs, df], axis=0)
#dfs.to_csv("gene_expression.tsv", header=True, index=True, sep="\t")
# Sus scrofa
#head -n 1 ../../../version1/pig.gene_tpm.tsv > ../Sus_scrofa/ORgene_expression.tpm.tsv 
#grep -f ../Sus_scrofa.Ensembl_ORgene.txt ../../../version1/pig.gene_tpm.tsv | awk -F "\t" -v OFS="\t" '{print}' >> ../Sus_scrofa/ORgene_expression.tpm.tsv
#其实pig.gene_tpm.tsv中存在样本重复的情况，而我sample2tissue使用的是metada的Sub categories
```
##### step4：分组组织的表达热图

animalGTEx涉及的组织和样本数目庞大，因此进行分组上色

```
#04_1.preprocess.py
import pandas as pd
from more_itertools import chunked
import os

os.system("mkdir -p output/step4_global_heatmap")
def execute(species):
    df = pd.read_table(f"output/step3_animalGTEx/{species}/sample2tissue.tsv", header=0, sep="\t")
    tissues = pd.read_table(f"output/step3_animalGTEx/{species}/tissue.manual_sorted.txt", header=None).loc[:, 0].tolist()
    #tissues = df["tissue"].drop_duplicates().tolist()
    n = 0
    for group in chunked(tissues, 9):
        n += 1
        df[f"group{n}"] = df["tissue"].apply(lambda tissue: tissue if tissue in group else "white")
    df = df.drop(columns=["tissue"])
    df.to_csv(f"output/step4_global_heatmap/{species}.grouped_tissue.tsv", header=True, index=False, sep="\t")

def execute(species):
    df = pd.read_table(f"output/step3_animalGTEx/{species}/sample2tissue.tsv", header=0, sep="\t")
    df0 = pd.read_table(f"output/step3_animalGTEx/{species}/tissue.manual_sorted.txt", header=0, sep="\t", index_col=0)
    for group in df0["group"].drop_duplicates():
        tissues = df0.loc[df0["group"]==group, :].index.tolist()
        df[group] = df["tissue"].apply(lambda tissue: tissue if tissue in tissues else "white")
    n = 0
    df = df.drop(columns=["tissue"])
    df.to_csv(f"output/step4_global_heatmap/{species}.grouped_tissue.tsv", header=True, index=False, sep="\t")

execute("Bos_taurus")
#execute("Sus_scrofa")
```
```
#04_2.group_heatmap.R
library(pheatmap)
# Bos taurus
plot_heatmap1 <- function(df, df_col, color_list, species, output) {
    p <- pheatmap(df,
        # cellwidth=100, cellheight=18,
        fontsize=4, 
        # labels_col=groups,
        angle_col="90", 
        #cluster_cols = FALSE,
        #cluster_rows = FALSE,
        show_rownames = FALSE,
        show_colnames = FALSE,
        border_color = "black",
        #display_number=T,
        color=colorRampPalette(c("#4576B4", "white", "#DA3428"))(50),
        # color=colorRampPalette(c("white", "#DA3428"))(50),
        main = species,
        #annotation_row = df_row, 
        annotation_col = df_col,
        annotation_colors = color_list,
        )
    tiff(output, width=24, height=16, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

# Sus_scrofa
plot_heatmap2 <- function(df, df_col, color_list, species, output) {
    p <- pheatmap(df,
        # cellwidth=100, cellheight=18,
        fontsize=4, 
        # labels_col=groups,
        angle_col="90", 
        cluster_cols = FALSE,
        cluster_rows = FALSE,
        show_rownames = FALSE,
        show_colnames = FALSE,
        border_color = "black",
        #display_number=T,
        color=colorRampPalette(c("#4576B4", "white", "#DA3428"))(50),
        # color=colorRampPalette(c("white", "#DA3428"))(50),
        main = species,
        #annotation_row = df_row, 
        annotation_col = df_col,
        annotation_colors = color_list,
        )
    tiff(output, width=24, height=16, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

execute <- function(species) {
    grouped_tissue <- paste0("output/step4_global_heatmap/", species, ".grouped_tissue.tsv")
    sample2tissue <- paste0("output/step3_animalGTEx/", species, "/sample2tissue.tsv")
    gene_expression <- paste0("output/step3_animalGTEx/", species, "/ORgene_expression.tpm.tsv")
    output <- paste0("output/step4_global_heatmap/", species, ".ORgene_expression.heatmap.tiff")

    #df_row <- read.table("gene2community.tsv", header=TRUE, sep="\t", row.names=1)
    df_col <- read.table(grouped_tissue, header=TRUE, sep="\t", row.names=1)
    df0 <- read.table(sample2tissue, header=TRUE, sep="\t", row.names=1)
    df <- read.table(gene_expression, header=TRUE, sep="\t", row.names=1)
    df <- log10(df + 0.01)
    color_list <- list()
    colors <- c('white', '#e6194B', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#42d4f4', '#f032e6', '#fabed4')
    for (group in rev(colnames(df_col))) {
        tissues <- unique(df_col[group])
        names(colors) <- c("white", tissues[tissues!="white"])
        color_list[[group]] <- colors
    }
    
    if (species == "Bos_taurus") {
        plot_heatmap1(df, df_col, color_list, species, output)
    } else {
        plot_heatmap2(df, df_col, color_list, species, output)}
    }

execute("Bos_taurus")
#execute("Sus_scrofa")
```
Bos taurus

![image-20240403225034992](0记录本/image-20240403225034992.png)

Sus scrofa

![image-20240403224943448](0记录本/image-20240403224943448.png)

##### step5：计算组织表达量的平均值和标准差和绘制气泡图

```
#05_1.mean_std.py
import pandas as pd
import os
def execute(species):
    #输入
    expression = f"output/step3_animalGTEx/{species}/ORgene_expression.tpm.tsv"
    sample2tissue = f"output/step3_animalGTEx/{species}/sample2tissue.tsv"
    os.system("mkdir -p output/step5_tissue_specific") ; output = f"output/step5_tissue_specific/{species}.ORgene_expression.mean_std.tsv"

    #样本名改为组织名
    df = pd.read_table(expression, header=0, index_col=0, sep="\t")
    df0 = pd.read_table(sample2tissue, header=0, index_col=0, sep="\t")
    df.columns = [df0.loc[i, "tissue"] for i in df.columns]
    
    mean_df = df.transpose().groupby(level=0).mean().transpose().fillna(0)
    std_df = df.transpose().groupby(level=0).std().transpose().fillna(0)
    
    lines = []
    for tissue in mean_df.columns:
        for gene in mean_df.index:
            mean, std = mean_df.loc[gene, tissue], std_df.loc[gene, tissue]
            lines.append([tissue, gene, mean, std])
            #f.write(f"{tissue}\t{gene}\t{mean}\t{std}\n")
    pd.DataFrame(lines, columns=["tissue", "gene", "mean", "std"]).to_csv(output, header=True, index=False, sep="\t")
execute("Bos_taurus")
execute("Sus_scrofa")
```
```
#05_2.bubble_chart.R
library(ggplot2)
library(viridis)

execute1 <- function(df) {
    df <- df[which(df$mean > 1), ]
    p <- ggplot(df, aes(x=gene, y=tissue, color=std, size=mean)) + geom_point()
    #p <- p + scale_color_gradient(low = "red", high = "green") + scale_size_continuous(range = c(0.5, 10), breaks=c(5, 10, 15, 20, 25, 30, 35, 40))
    p <- p + scale_color_gradient(low = "red", high = "green") + scale_size_continuous(range = c(0.5, 10))
    p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
    p <- p + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_text(size=12, hjust=1, vjust=0.5), axis.title=element_text(size=12))
    tiff("output/step5_tissue_specific/Bos_taurus.ORgene_expression.mean_std.1.tiff", width=48, height=36, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

execute2 <- function(df) {
    df <- df[which(df$mean > 0.1 & df$mean <= 1), ]
    p <- ggplot(df, aes(x=gene, y=tissue, color=std, size=mean)) + geom_point(alpha=0.5)
    p <- p + scale_color_gradient(low = "red", high = "green") + scale_size_continuous(range = c(0.5, 10), breaks=c(0.2, 0.4, 0.6, 0.8, 1))
    p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
    p <- p + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_text(size=12, hjust=1, vjust=0.5), axis.title=element_text(size=12))
    tiff("output/step5_tissue_specific/Bos_taurus.ORgene_expression.mean_std.2.tiff", width=48, height=36, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

execute3 <- function(df) {
    df <- df[which(df$mean > 1), ]
    p <- ggplot(df, aes(x=gene, y=tissue, color=std, size=mean)) + geom_point()
    p <- p + scale_color_gradient(low = "red", high = "green") + scale_size_continuous(range = c(0.5, 10), breaks=c(5, 10, 15, 20, 25, 30, 35, 40))
    p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
    p <- p + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_text(size=12, hjust=1, vjust=0.5), axis.title=element_text(size=12))
    tiff("output/step5_tissue_specific/Sus_scrofa.ORgene_expression.mean_std.1.tiff", width=24, height=24, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

execute4 <- function(df) {
    df <- df[which(df$mean > 0.1 & df$mean <= 1), ]
    p <- ggplot(df, aes(x=gene, y=tissue, color=std, size=mean)) + geom_point(alpha=0.5)
    p <- p + scale_color_gradient(low = "red", high = "green") + scale_size_continuous(range = c(0.5, 10), breaks=c(0.2, 0.4, 0.6, 0.8, 1))
    p <- p + theme_bw() + theme(panel.border=element_blank(), panel.grid.major=element_blank(), panel.grid.minor=element_blank(), axis.line=element_line(colour="black"))
    p <- p + theme(axis.text.x=element_blank(), axis.ticks.x=element_blank(), axis.text.y=element_text(size=12, hjust=1, vjust=0.5), axis.title=element_text(size=12))
    tiff("output/step5_tissue_specific/Sus_scrofa.ORgene_expression.mean_std.2.tiff", width=24, height=24, units="cm", res=600, compression="lzw")
    print(p)
    dev.off()
}

# Bos taurus
tsv <- "output/step5_tissue_specific/Bos_taurus.ORgene_expression.mean_std.tsv"
df <- read.table(tsv, header=T, sep="\t")
execute1(df)
execute2(df)

# Sus scrofa
tsv <- "output/step5_tissue_specific/Sus_scrofa.ORgene_expression.mean_std.tsv"
df <- read.table(tsv, header=T, sep="\t")
execute3(df)
execute4(df)
```

Bos taurus

![image-20240403225131490](0记录本/image-20240403225131490.png)

Sus scrofa

![image-20240403225152100](0记录本/image-20240403225152100.png)

### 20240403：脂肪细胞DRS数据中OR基因表达（未整理）

##### step1：已有bam文件用isoquant进行定量

/home/penglingwei/OR/transcriptome/adipose_drs

```shell
isoquant=isoquant.py
genome=/home/penglingwei/ONT/ref/Bos_taurus.ARS-UCD1.2.dna_sm.toplevel.fa
gtf=/home/penglingwei/ONT/ref/Bos_taurus.ARS-UCD1.2.104.gtf
thread=4
sample_folder=quant/${sample} ; mkdir -p ${sample_folder}
cat sample2bam.tsv | while IFS=$'\t' read -r sample bam
do
break
${isoquant} -d nanopore --model_construction_strategy sensitive_ont --reference ${genome} --genedb ${gtf} -t ${thread} --bam ${bam} --labels ${sample} --prefix ${sample} --output ${sample_folder}
done

python3 - << END
import os
import pandas as pd
import os

dfs = pd.DataFrame({"gene": []})
for sample in ["PA1", "PA2", "PA3", "DA1", "DA2", "DA3"]:
   df = pd.read_table(f"quant/{sample}/{sample}.gene_tpm.tsv", header=None, sep="\t", comment="#")
   df.columns = ["gene", sample]
   dfs = pd.merge(dfs, df, how="outer", on="gene")
dfs.fillna(0).to_csv("gene_expression.tsv", header=True, index=False, sep="\t")
END
```

##### step2：获得Ensembl release104版本的OR基因





### 20240411：humanGTEx和chichenGTEx数据库中OR基因样本表达（待整理）

##### humanGTEx表达数据预处理

(/share/home/yzwl_zhouy/penglingwei/OR/transcriptome/animalGTEx_sample/output/step3_animalGTEx/Homo_sapiens/raw)

整理成表达矩阵和样本组织表

```shell
#!/bin/bash
for url in `cat download_url.txt`
do
    break
    tissue=`echo ${url} | awk -F "/" '{print $NF}' | sed "s/gene_tpm_2017-06-05_v8_//g" | sed "s/.gct.gz//g"`
    echo ${tissue}
    wget ${url} -O gene_tpm/${tissue}.tsv.gz
done

# 生成表达矩阵
awk 'NR>2' gene_tpm/liver.tsv | cut -f 2 > gene_expression.tpm.tsv
for tsv in `ls gene_tpm/*tsv`
do
 break
 echo ${tsv}
 paste gene_expression.tpm.tsv <(awk 'NR>2' ${tsv}  | cut -f 4- ) > tmp 
 mv tmp gene_expression.tpm.tsv 
done

# 生成样本组织对应关系
> sample2tissue
for tsv in `ls gene_tpm/*tsv`
do
 tissue=`basename ${tsv} | cut -d "." -f 1`
 echo ${tsv}
 awk 'NR>2' ${tsv}  | cut -f 4- | head -n 1 | sed "s/\t/\n/g" | awk -v s=${tissue} '{print $1"\t"s}' >> sample2tissue
done
```



### 20240415：

```shell
execute () {
	sample=$1 ; bam=$2
	reads_number=`samtools flagstat -@ 4 ${bam} | awk 'NR==1' | awk '{print $1}'`
	mapping_rate=`samtools flagstat -@ 4 ${bam} | awk 'NR==7' | cut -d "(" -f 2 | awk '{print $1}'`
	echo -e "${sample}\t${reads_number}\t${mapping_rate}" >> sample_statistic.tsv
	}
	
export -f execute
> sample_statistic.tsv
csv=/home/penglingwei/pan_transcriptome/ngs_process/sample_bam.csv
grep -v "#" ${csv} | parallel --colsep "," -j 10 --keep-order "execute {1} {2}"
```



### 20240507：设计OR基因的qPCR引物

分别设计OR基因的引物，再确定共享的引物

```python
# python3.10版本的primer3

from primer3 import design_primers
import pyfastx
import pandas as pd

PRIMER_PARAMETERS = {
    'PRIMER_OPT_SIZE': 20,
    'PRIMER_PICK_INTERNAL_OLIGO': 1,
    'PRIMER_INTERNAL_MAX_SELF_END': 8,
    'PRIMER_MIN_SIZE': 18,
    'PRIMER_MAX_SIZE': 25,
    'PRIMER_OPT_TM': 60.0,
    'PRIMER_MIN_TM': 55.0,
    'PRIMER_MAX_TM': 65.0,
    'PRIMER_PAIR_MAX_DIFF_TM': 4.0, # 两个引物之间的 TM 值最多相差4摄氏度
    'PRIMER_MIN_GC': 40.0,
    'PRIMER_MAX_GC': 60.0,
    'PRIMER_MAX_POLY_X': 100,
    'PRIMER_INTERNAL_MAX_POLY_X': 100,
    'PRIMER_SALT_MONOVALENT': 50.0,
    'PRIMER_DNA_CONC': 50.0,
    'PRIMER_MAX_NS_ACCEPTED': 0,
    'PRIMER_MAX_SELF_ANY': 12,
    'PRIMER_MAX_SELF_END': 8,
    'PRIMER_PAIR_MAX_COMPL_ANY': 12,
    'PRIMER_PAIR_MAX_COMPL_END': 8,
    'PRIMER_PRODUCT_SIZE_RANGE': [100, 300],
    'PRIMER_NUM_RETURN': 50
    }

def designPrimer(name, seq):
    # primer3设计引物
    primers = design_primers(
        {
            'SEQUENCE_ID': name,
            'SEQUENCE_TEMPLATE': seq,
            'SEQUENCE_INCLUDED_REGION': [0, len(seq)-1]
        }, PRIMER_PARAMETERS
    )

    # 处理输出结果
    dfs = pd.DataFrame()
    for PRIMER_LEFT, PRIMER_RIGHT, PRIMER_PAIR, PRIMER_INTERNAL in zip(primers["PRIMER_LEFT"], primers["PRIMER_RIGHT"], primers["PRIMER_PAIR"], primers["PRIMER_INTERNAL"]):
        df1 = pd.DataFrame([PRIMER_LEFT]) ; df1.columns = [f"LEFT:{i}" for i in df1.columns]
        df2 = pd.DataFrame([PRIMER_RIGHT]) ; df2.columns = [f"RIGHT:{i}" for i in df2.columns]
        df3 = pd.DataFrame([PRIMER_PAIR]) ; df3.columns = [f"PAIR:{i}" for i in df3.columns]
        df4 = pd.DataFrame([PRIMER_INTERNAL]) ; df4.columns = [f"INTERNAL:{i}" for i in df4.columns]
        df = pd.concat([df1, df2, df3, df4], axis=1)
        dfs = pd.concat([dfs, df], axis=0)    
    return dfs

fa = pyfastx.Fastx("Sus_scrofa.OR_gene.fasta")
dfs = pd.DataFrame()
for name, seq in fa:
    df = designPrimer(name, seq)
    df["name"] = name
    dfs = pd.concat([dfs, df], axis=0)
dfs.to_csv("primers.tsv", header=True, index=False, sep="\t")
```

结果：1500+的OR基因得到的最佳的引物有为~20个OR基因共享
